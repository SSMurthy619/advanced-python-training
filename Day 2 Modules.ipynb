{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc8cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role of metaclasses in custom type creation\n",
    "#  Example demonstration: interface class + derived classes\n",
    "#  Practical use case in framework design or ORMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ea3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a metaclass?\n",
    "# A metaclass is something that creates classes.\n",
    "# - A class creates objects\n",
    "# - A metaclass creates classes\n",
    "\n",
    "# You use metaclasses when you want to control or modify class creation automatically, like:\n",
    "# - enforcing rules (“every class must have a method called save()”)\n",
    "# - auto-registering classes (plugin systems)\n",
    "# - creating APIs / ORMs (Django models are a classic example)\n",
    "# - validating class attributes at definition time\n",
    "# - automatically adding methods or fields\n",
    "# Metaclasses help frameworks do “magic” safely and consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971a50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class A:\n",
    "#     pass\n",
    "\n",
    "# So the default metaclass in Python is:\n",
    "# type\n",
    "\n",
    "# x = 10\n",
    "# # x is an object of class int\n",
    "\n",
    "# Classes come from metaclasses:\n",
    "# class A:\n",
    "#     pass\n",
    "# # A is an object too, created by metaclass \"type\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81510c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Show that classes are created by type\n",
    "\n",
    "class A:\n",
    "    pass\n",
    "\n",
    "print(type(A))\n",
    "# OUTPUT: <class 'type'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee91277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create a class dynamically using type\n",
    "\n",
    "# Normally we write:\n",
    "class Person:\n",
    "    def greet(self):\n",
    "        return \"Hello\"\n",
    "\n",
    "# But you can create the same class using type:\n",
    "def greet(self):\n",
    "    return \"Hello\"\n",
    "\n",
    "Person = type(\n",
    "    \"Person\",          # Class name\n",
    "    (),                # Base classes (empty tuple means no custom base)\n",
    "    {\"greet\": greet}   # Attributes/methods of the class\n",
    ")\n",
    "\n",
    "p = Person()\n",
    "print(p.greet())\n",
    "# OUTPUT: Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cff880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def greet(self):\n",
    "        return \"Hello\"\n",
    "\n",
    "p = Person()\n",
    "print(p.greet())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241a28a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alling p.greet() is equivalent to:\n",
    "greet(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e74a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(self):\n",
    "    return \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39569cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(abc(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608187f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Custom Metaclass\n",
    "# A custom metaclass is created by subclassing type.\n",
    "\n",
    "class MyMeta(type):\n",
    "    pass\n",
    "# To use it:\n",
    "class MyClass(metaclass=MyMeta):\n",
    "    pass\n",
    "# At this point, MyMeta controls how MyClass is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99078591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating class: Sample\n"
     ]
    }
   ],
   "source": [
    "# The __new__ Method in a Metaclass\n",
    "# The most important method in a metaclass is __new__.\n",
    "# It runs when the class itself is being created, not when instances are created.\n",
    "\n",
    "class DebugMeta(type):\n",
    "    def __new__(cls, name, bases, namespace):\n",
    "        print(f\"Creating class: {name}\")\n",
    "        return super().__new__(cls, name, bases, namespace)\n",
    "# Usage:\n",
    "\n",
    "class Sample(metaclass=DebugMeta):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acef7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforcing Rules at Class Creation Time\n",
    "# Metaclasses can enforce rules on class definitions.\n",
    "\n",
    "class RequireMethodMeta(type):\n",
    "    def __new__(cls, name, bases, namespace):\n",
    "        if \"process\" not in namespace:\n",
    "            raise TypeError(\"Classes must define a 'process' method\")\n",
    "        return super().__new__(cls, name, bases, namespace)\n",
    "\n",
    "# Usage:\n",
    "class ValidClass(metaclass=RequireMethodMeta):\n",
    "    def process(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d5b348",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Classes must define a 'process' method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mInvalidClass\u001b[39;00m(metaclass\u001b[38;5;241m=\u001b[39mRequireMethodMeta):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mRequireMethodMeta.__new__\u001b[0;34m(cls, name, bases, namespace)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, bases, namespace):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace:\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses must define a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, bases, namespace)\n",
      "\u001b[0;31mTypeError\u001b[0m: Classes must define a 'process' method"
     ]
    }
   ],
   "source": [
    "class InvalidClass(metaclass=RequireMethodMeta):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "441e7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metaclasses vs Abstract Base Classes\n",
    "# Metaclasses and ABCs solve related but different problems.\n",
    "# ABCs enforce instance-level behavior\n",
    "# Metaclasses enforce class-level structure\n",
    "# ABCs check what methods exist after the class is created. Metaclasses control how the class is created in the first place.\n",
    "\n",
    "# This is why ABCs themselves are implemented using metaclasses internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3bc45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PluginA': <class '__main__.PluginA'>, 'PluginB': <class '__main__.PluginB'>}\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: Automatic Class Registration\n",
    "# Metaclasses are often used to automatically register classes.\n",
    "\n",
    "class RegistryMeta(type):\n",
    "    registry = {}\n",
    "\n",
    "    def __new__(cls, name, bases, namespace):\n",
    "        new_class = super().__new__(cls, name, bases, namespace)\n",
    "        cls.registry[name] = new_class\n",
    "        return new_class\n",
    "# Usage:\n",
    "\n",
    "class PluginA(metaclass=RegistryMeta):\n",
    "    pass\n",
    "\n",
    "class PluginB(metaclass=RegistryMeta):\n",
    "    pass\n",
    "\n",
    "print(RegistryMeta.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5722db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can:\n",
    "# auto-register plugins\n",
    "# build frameworks\n",
    "# eliminate manual bookkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d04c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When Metaclasses Should Be Used\n",
    "# Metaclasses are appropriate when:\n",
    "# Rules must be enforced at class definition time\n",
    "# Classes must be automatically modified or registered\n",
    "# Framework-level behavior is required\n",
    "\n",
    "# They should be avoided for:\n",
    "# Simple behavior reuse\n",
    "# Instance-level customization\n",
    "# Problems solvable with inheritance or decorators\n",
    "\n",
    "# Metaclasses are powerful but should be used sparingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Building a Rule-Enforcing Metaclass\n",
    "# Create a custom metaclass that:\n",
    "\n",
    "# Requires all classes to define a run() method\n",
    "# Prints the class name when the class is created\n",
    "# Requirements:\n",
    "\n",
    "# Use __new__ in the metaclass\n",
    "# Raise an error for invalid classes\n",
    "# Demonstrate with one valid and one invalid class\n",
    "# Objective:\n",
    "\n",
    "# Understand class creation control\n",
    "# Observe metaclass execution timing\n",
    "# Apply enforcement logic correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2726f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c3bc57",
   "metadata": {},
   "source": [
    "# Example Demonstration: Interface Class and Derived Classes\n",
    "\n",
    "## What Is an Interface-Like Design in Python?\n",
    "\n",
    "Python does not have interfaces as a separate language construct (unlike Java or C#). Instead, Python achieves the same goal using **Abstract Base Classes (ABCs)**.\n",
    "\n",
    "An interface-like design means:\n",
    "\n",
    "* Defining **what methods must exist**\n",
    "* Not defining **how those methods work**\n",
    "* Allowing multiple implementations with different internal logic\n",
    "* Enforcing correctness at class creation or instantiation time\n",
    "\n",
    "This pattern is extremely common in real-world Python systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement Without an Interface\n",
    "\n",
    "Consider a system where different components are expected to perform the same action.\n",
    "\n",
    "```python\n",
    "class EmailService:\n",
    "    def send(self, message):\n",
    "        print(\"Sending email:\", message)\n",
    "\n",
    "class SMSService:\n",
    "    def deliver(self, message):\n",
    "        print(\"Sending SMS:\", message)\n",
    "```\n",
    "\n",
    "Issues with this approach:\n",
    "\n",
    "* Method names are inconsistent\n",
    "* There is no enforcement of behavior\n",
    "* Code using these classes must handle each type differently\n",
    "* Errors appear only at runtime\n",
    "\n",
    "This makes the system fragile and hard to extend.\n",
    "\n",
    "---\n",
    "\n",
    "## Defining an Interface Using an Abstract Base Class\n",
    "\n",
    "An Abstract Base Class defines the **required contract**.\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class NotificationService(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def send(self, message):\n",
    "        pass\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `NotificationService` defines the expected behavior\n",
    "* Any derived class must implement `send`\n",
    "* The base class itself cannot be instantiated\n",
    "\n",
    "This acts as an interface.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating Concrete Implementations\n",
    "\n",
    "### Email Notification Implementation\n",
    "\n",
    "```python\n",
    "class EmailNotification(NotificationService):\n",
    "\n",
    "    def send(self, message):\n",
    "        print(f\"Email sent: {message}\")\n",
    "```\n",
    "\n",
    "### SMS Notification Implementation\n",
    "\n",
    "```python\n",
    "class SMSNotification(NotificationService):\n",
    "\n",
    "    def send(self, message):\n",
    "        print(f\"SMS sent: {message}\")\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Both classes implement the same method\n",
    "* Internal behavior differs\n",
    "* External usage remains consistent\n",
    "\n",
    "---\n",
    "\n",
    "## Using the Interface in Client Code\n",
    "\n",
    "```python\n",
    "def notify(service: NotificationService, message):\n",
    "    service.send(message)\n",
    "```\n",
    "\n",
    "Usage:\n",
    "\n",
    "```python\n",
    "email = EmailNotification()\n",
    "sms = SMSNotification()\n",
    "\n",
    "notify(email, \"Welcome\")\n",
    "notify(sms, \"Your OTP is 1234\")\n",
    "```\n",
    "\n",
    "Key observation:\n",
    "\n",
    "* Client code depends on the interface, not implementations\n",
    "* New implementations can be added without changing existing logic\n",
    "\n",
    "---\n",
    "\n",
    "## Enforcement of the Contract\n",
    "\n",
    "If a derived class does not implement the required method, it fails early.\n",
    "\n",
    "```python\n",
    "class PushNotification(NotificationService):\n",
    "    pass\n",
    "```\n",
    "\n",
    "Attempting to instantiate this class raises an error because `send` is not implemented.\n",
    "\n",
    "This prevents incomplete implementations from entering the system.\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Pattern Matters in Real Applications\n",
    "\n",
    "This interface-based design enables:\n",
    "\n",
    "* Clean separation of concerns\n",
    "* Easier testing using mock implementations\n",
    "* Safe extension of systems\n",
    "* Clear architectural boundaries\n",
    "\n",
    "It is widely used in:\n",
    "\n",
    "* Notification systems\n",
    "* Payment gateways\n",
    "* Logging frameworks\n",
    "* Storage backends\n",
    "* Plugin architectures\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: Interface and Derived Classes\n",
    "\n",
    "This code must be saved as `interface_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python interface_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DataExporter(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def export(self, data):\n",
    "        pass\n",
    "\n",
    "class CSVExporter(DataExporter):\n",
    "\n",
    "    def export(self, data):\n",
    "        print(\"Exporting data to CSV:\", data)\n",
    "\n",
    "class JSONExporter(DataExporter):\n",
    "\n",
    "    def export(self, data):\n",
    "        print(\"Exporting data to JSON:\", data)\n",
    "\n",
    "def run_export(exporter: DataExporter, data):\n",
    "    exporter.export(data)\n",
    "\n",
    "csv = CSVExporter()\n",
    "json_exporter = JSONExporter()\n",
    "\n",
    "run_export(csv, [1, 2, 3])\n",
    "run_export(json_exporter, {\"a\": 1, \"b\": 2})\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* The same function works with multiple implementations\n",
    "* Behavior changes without changing the calling code\n",
    "* The interface enforces correctness\n",
    "\n",
    "---\n",
    "\n",
    "## Combining ABCs with Shared Logic\n",
    "\n",
    "Abstract base classes can also include shared behavior.\n",
    "\n",
    "```python\n",
    "class BaseExporter(ABC):\n",
    "\n",
    "    def validate(self, data):\n",
    "        if not data:\n",
    "            raise ValueError(\"No data to export\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def export(self, data):\n",
    "        pass\n",
    "```\n",
    "\n",
    "Derived classes can reuse `validate` while implementing `export`.\n",
    "\n",
    "This balances flexibility with code reuse.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Designing an Interface with Multiple Implementations\n",
    "\n",
    "Create an interface for a payment system.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Abstract base class `PaymentGateway`\n",
    "* Abstract method `process(amount)`\n",
    "* Two implementations:\n",
    "\n",
    "  * Credit card payment\n",
    "  * Wallet payment\n",
    "* A function that accepts any payment gateway and processes a payment\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Apply interface-based design\n",
    "* Enforce method implementation\n",
    "* Use polymorphism correctly\n",
    "\n",
    "The solution should demonstrate that:\n",
    "\n",
    "* All implementations follow the same contract\n",
    "* Client code remains unchanged when adding new gateways\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac635809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7af4c3",
   "metadata": {},
   "source": [
    "# Practical Use Case in Framework Design or ORMs\n",
    "\n",
    "## Why Frameworks and ORMs Need Strong Structure\n",
    "\n",
    "Frameworks and ORMs are not simple scripts. They are **extensible systems** where:\n",
    "\n",
    "* New components are added over time\n",
    "* Multiple developers work independently\n",
    "* User-written code must integrate safely\n",
    "* Errors must be detected early\n",
    "\n",
    "To achieve this, frameworks rely heavily on:\n",
    "\n",
    "* Interfaces (ABCs)\n",
    "* Controlled class creation\n",
    "* Convention enforcement\n",
    "* Automatic registration of components\n",
    "\n",
    "This section demonstrates how **ABCs and metaclasses** are used together in a realistic framework-style design.\n",
    "\n",
    "---\n",
    "\n",
    "## Realistic Problem Scenario\n",
    "\n",
    "Assume a framework that supports **multiple database backends**, such as:\n",
    "\n",
    "* SQLite\n",
    "* PostgreSQL\n",
    "* MySQL\n",
    "\n",
    "Each backend must:\n",
    "\n",
    "* Connect to the database\n",
    "* Execute queries\n",
    "* Close connections\n",
    "\n",
    "The framework must:\n",
    "\n",
    "* Enforce a common interface\n",
    "* Prevent incomplete implementations\n",
    "* Automatically register supported backends\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Defining the Interface Using an Abstract Base Class\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DatabaseBackend(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def connect(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def execute(self, query):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def close(self):\n",
    "        pass\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The interface defines **what operations are mandatory**\n",
    "* No backend-specific logic exists here\n",
    "* All implementations must follow the same contract\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Why Interface Alone Is Not Enough\n",
    "\n",
    "Even with an ABC:\n",
    "\n",
    "* Developers can forget to register new backends\n",
    "* The framework has no centralized view of available implementations\n",
    "* Manual registration leads to errors and duplication\n",
    "\n",
    "Frameworks solve this by **automating registration**.\n",
    "\n",
    "This is where metaclasses are used.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Metaclass for Automatic Backend Registration\n",
    "\n",
    "```python\n",
    "class BackendRegistryMeta(type):\n",
    "    registry = {}\n",
    "\n",
    "    def __new__(cls, name, bases, namespace):\n",
    "        new_class = super().__new__(cls, name, bases, namespace)\n",
    "\n",
    "        if name != \"BaseBackend\":\n",
    "            cls.registry[name] = new_class\n",
    "\n",
    "        return new_class\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Every backend class is registered at class creation time\n",
    "* No manual registration code is needed\n",
    "* The framework always knows available backends\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Combining ABC and Metaclass\n",
    "\n",
    "```python\n",
    "class BaseBackend(DatabaseBackend, metaclass=BackendRegistryMeta):\n",
    "    pass\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `DatabaseBackend` enforces method implementation\n",
    "* `BackendRegistryMeta` controls class creation\n",
    "* The base class itself is excluded from registration\n",
    "\n",
    "This pattern is extremely common in ORMs and frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Concrete Backend Implementations\n",
    "\n",
    "### SQLite Backend\n",
    "\n",
    "```python\n",
    "class SQLiteBackend(BaseBackend):\n",
    "\n",
    "    def connect(self):\n",
    "        print(\"Connecting to SQLite\")\n",
    "\n",
    "    def execute(self, query):\n",
    "        print(f\"Executing SQLite query: {query}\")\n",
    "\n",
    "    def close(self):\n",
    "        print(\"Closing SQLite connection\")\n",
    "```\n",
    "\n",
    "### PostgreSQL Backend\n",
    "\n",
    "```python\n",
    "class PostgresBackend(BaseBackend):\n",
    "\n",
    "    def connect(self):\n",
    "        print(\"Connecting to PostgreSQL\")\n",
    "\n",
    "    def execute(self, query):\n",
    "        print(f\"Executing PostgreSQL query: {query}\")\n",
    "\n",
    "    def close(self):\n",
    "        print(\"Closing PostgreSQL connection\")\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Both backends implement the same interface\n",
    "* Both are automatically registered\n",
    "* The framework does not need to know implementation details\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Framework-Level Usage\n",
    "\n",
    "```python\n",
    "def get_backend(name):\n",
    "    backend_class = BackendRegistryMeta.registry.get(name)\n",
    "    if not backend_class:\n",
    "        raise ValueError(\"Unsupported backend\")\n",
    "    return backend_class()\n",
    "```\n",
    "\n",
    "Usage:\n",
    "\n",
    "```python\n",
    "backend = get_backend(\"SQLiteBackend\")\n",
    "backend.connect()\n",
    "backend.execute(\"SELECT * FROM users\")\n",
    "backend.close()\n",
    "```\n",
    "\n",
    "Key observation:\n",
    "\n",
    "* Backend selection is dynamic\n",
    "* Client code depends only on the interface\n",
    "* New backends can be added without changing framework logic\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: ORM-Style Backend System\n",
    "\n",
    "This code must be saved as `orm_backend_framework_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python orm_backend_framework_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BackendRegistryMeta(type):\n",
    "    registry = {}\n",
    "\n",
    "    def __new__(cls, name, bases, namespace):\n",
    "        new_class = super().__new__(cls, name, bases, namespace)\n",
    "        if name != \"BaseBackend\":\n",
    "            cls.registry[name] = new_class\n",
    "        return new_class\n",
    "\n",
    "class DatabaseBackend(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def connect(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def execute(self, query):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "class BaseBackend(DatabaseBackend, metaclass=BackendRegistryMeta):\n",
    "    pass\n",
    "\n",
    "class SQLiteBackend(BaseBackend):\n",
    "\n",
    "    def connect(self):\n",
    "        print(\"SQLite connected\")\n",
    "\n",
    "    def execute(self, query):\n",
    "        print(f\"SQLite executing: {query}\")\n",
    "\n",
    "    def close(self):\n",
    "        print(\"SQLite closed\")\n",
    "\n",
    "class MySQLBackend(BaseBackend):\n",
    "\n",
    "    def connect(self):\n",
    "        print(\"MySQL connected\")\n",
    "\n",
    "    def execute(self, query):\n",
    "        print(f\"MySQL executing: {query}\")\n",
    "\n",
    "    def close(self):\n",
    "        print(\"MySQL closed\")\n",
    "\n",
    "def get_backend(name):\n",
    "    return BackendRegistryMeta.registry[name]()\n",
    "\n",
    "backend = get_backend(\"SQLiteBackend\")\n",
    "backend.connect()\n",
    "backend.execute(\"SELECT * FROM products\")\n",
    "backend.close()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Why ORMs Use This Pattern\n",
    "\n",
    "Popular ORMs and frameworks use this exact approach to:\n",
    "\n",
    "* Enforce model structure\n",
    "* Register models automatically\n",
    "* Validate schema definitions\n",
    "* Generate queries dynamically\n",
    "* Support multiple databases cleanly\n",
    "\n",
    "Examples include:\n",
    "\n",
    "* Database backends\n",
    "* Field definitions\n",
    "* Query expressions\n",
    "* Migration systems\n",
    "\n",
    "This pattern scales well as frameworks grow.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Designing a Mini ORM Component\n",
    "\n",
    "Design a mini framework for data storage.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Abstract base class `StorageEngine`\n",
    "* Methods: `save(data)`, `load()`\n",
    "* Use a metaclass to auto-register implementations\n",
    "* Implement two engines:\n",
    "\n",
    "  * In-memory storage\n",
    "  * File-based storage\n",
    "* Provide a factory function to select storage by name\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Apply ABCs for interface enforcement\n",
    "* Apply metaclasses for registration\n",
    "* Simulate real framework behavior\n",
    "\n",
    "The solution should show that:\n",
    "\n",
    "* All engines follow the same contract\n",
    "* New engines are auto-discovered\n",
    "* Client code remains unchanged\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b137a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0344b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8158378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 4A: Multi-threading \n",
    "# • Understanding Threads and the GIL \n",
    "# • threading module essentials \n",
    "# • Synchronization using Locks, Events, Semaphores, Queues \n",
    "# • Thread-safe data access and deadlock avoidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68619fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a thread?\n",
    "# A thread is a smaller unit of work that runs inside a program.\n",
    "# A single program (process) can run multiple threads that share the same memory.\n",
    "\n",
    "# What is multi-threading?\n",
    "# Multithreading means running more than one thread in the same program so tasks can overlap.\n",
    "\n",
    "# Why do we need threads?\n",
    "# Threads are useful when your program spends time waiting, like:\n",
    "# - waiting for network (API calls)\n",
    "# - waiting for files/database\n",
    "# - waiting/sleeping\n",
    "# While one thread is waiting, another thread can do work.\n",
    "\n",
    "# Important Terms:\n",
    "# 1. Process: a running program with its own memory (heavier)\n",
    "# 2. Thread: lightweight worker inside a process (shares memory)\n",
    "# 3. Concurrency: tasks overlap in time (switching happens)\n",
    "# 4. Parallelism: tasks run at the exact same time on multiple CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356e9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task started\n",
      "Task finished\n",
      "Task started\n",
      "Task finished\n",
      "Time taken: 4.007073879241943\n"
     ]
    }
   ],
   "source": [
    "# Normal program (single-thread)\n",
    "\n",
    "import time\n",
    "\n",
    "def task():\n",
    "    print(\"Task started\")\n",
    "    time.sleep(2)  # Pretend we are waiting for I/O\n",
    "    print(\"Task finished\")\n",
    "\n",
    "start = time.time()\n",
    "task()\n",
    "task()\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken:\", end - start)\n",
    "# OUTPUT (approx):\n",
    "# Task started\n",
    "# Task finished\n",
    "# Task started\n",
    "# Task finished\n",
    "# Time taken: ~4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aea6e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task started\n",
      "Task started\n",
      "Task finished\n",
      "Task finished\n",
      "Time taken: 2.005908250808716\n"
     ]
    }
   ],
   "source": [
    "# Same thing with threads (multithreading)\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def task():\n",
    "    print(\"Task started\")\n",
    "    time.sleep(2)   # waiting work (I/O-like)\n",
    "    print(\"Task finished\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "t1 = threading.Thread(target=task)  # create thread 1 (it will run task)\n",
    "t2 = threading.Thread(target=task)  # create thread 2\n",
    "\n",
    "t1.start()  # start thread 1\n",
    "t2.start()  # start thread 2\n",
    "\n",
    "t1.join()   # wait until thread 1 finishes\n",
    "t2.join()   # wait until thread 2 finishes\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "\n",
    "# OUTPUT (approx, order can vary):\n",
    "# Task started\n",
    "# Task started\n",
    "# Task finished\n",
    "# Task finished\n",
    "# Time taken: ~2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35fc96e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: before start\n",
      "Worker: starting\n",
      "Main: after start (worker may still be running)\n",
      "Worker: done\n",
      "Main: after join (worker must be finished now)\n"
     ]
    }
   ],
   "source": [
    "# Core Thread Concepts\n",
    "# start() vs join()\n",
    "# start() begins the thread’s work.\n",
    "# join() makes the main program wait until the thread completes.\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def task():\n",
    "    print(\"Worker: starting\")\n",
    "    time.sleep(1)\n",
    "    print(\"Worker: done\")\n",
    "\n",
    "t = threading.Thread(target=task)\n",
    "\n",
    "print(\"Main: before start\")\n",
    "t.start()\n",
    "print(\"Main: after start (worker may still be running)\")\n",
    "t.join()\n",
    "print(\"Main: after join (worker must be finished now)\")\n",
    "\n",
    "# OUTPUT (order may slightly vary, but join guarantees final order):\n",
    "# Main: before start\n",
    "# Worker: starting\n",
    "# Main: after start (worker may still be running)\n",
    "# Worker: done\n",
    "# Main: after join (worker must be finished now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4284123f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Asha\n"
     ]
    }
   ],
   "source": [
    "# 2) Passing arguments to a thread\n",
    "\n",
    "import threading\n",
    "\n",
    "def greet(name):\n",
    "    print(\"Hello\", name)\n",
    "\n",
    "t = threading.Thread(target=greet, args=(\"Asha\",))  # args must be a tuple\n",
    "t.start()\n",
    "t.join()\n",
    "\n",
    "# OUTPUT:\n",
    "# Hello Asha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8f678db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 9 16\n"
     ]
    }
   ],
   "source": [
    "# 3) Getting results back from threads\n",
    "# Threads don’t directly “return” like a normal function call.\n",
    "# Use a Queue (thread-safe) to collect results.\n",
    "\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "def square(n, out_q):\n",
    "    out_q.put(n * n)  # safely store result for main thread\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "t1 = threading.Thread(target=square, args=(3, q))\n",
    "t2 = threading.Thread(target=square, args=(4, q))\n",
    "\n",
    "t1.start(); t2.start()\n",
    "t1.join();  t2.join()\n",
    "\n",
    "print(\"Results:\", q.get(), q.get())\n",
    "# OUTPUT (order may vary):\n",
    "# Results: 9 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3760694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in: Worker-1\n"
     ]
    }
   ],
   "source": [
    "# 4) Naming threads (helps debugging)\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def task():\n",
    "    print(\"Running in:\", threading.current_thread().name)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "t = threading.Thread(target=task, name=\"Worker-1\")\n",
    "t.start()\n",
    "t.join()\n",
    "\n",
    "# OUTPUT:\n",
    "# Running in: Worker-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Main ends now. Program may exit even though background loop is infinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n",
      "Background working...\n"
     ]
    }
   ],
   "source": [
    "# # 5) Daemon threads (background helper threads)\n",
    "# # A daemon thread will not keep the program alive.\n",
    "# # If only daemon threads are left, Python may exit immediately.\n",
    "\n",
    "# import threading\n",
    "# import time\n",
    "\n",
    "# def background():\n",
    "#     while True:\n",
    "#         print(\"Background working...\")\n",
    "#         time.sleep(0.5)\n",
    "\n",
    "# t = threading.Thread(target=background, daemon=True)  # daemon thread\n",
    "# t.start()\n",
    "\n",
    "# time.sleep(1.2)\n",
    "# print(\"Main ends now. Program may exit even though background loop is infinite.\")\n",
    "\n",
    "# # OUTPUT (approx):\n",
    "# # Background working...\n",
    "# # Background working...\n",
    "# # Main ends now. Program may exit even though background loop is infinite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6888b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronization: When threads share data\n",
    "# When multiple threads access shared data, you can get race conditions (wrong results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5d3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 200000\n"
     ]
    }
   ],
   "source": [
    "# 6) Race condition example\n",
    "\n",
    "import threading\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100_000):\n",
    "        counter += 1  # not an atomic operation in Python\n",
    "\n",
    "t1 = threading.Thread(target=increment)\n",
    "t2 = threading.Thread(target=increment)\n",
    "\n",
    "t1.start(); t2.start()\n",
    "t1.join();  t2.join()\n",
    "\n",
    "print(\"Counter:\", counter)\n",
    "# OUTPUT: Often NOT 200000 (may be less due to race condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc19b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 200000\n"
     ]
    }
   ],
   "source": [
    "# 7) Fix using Lock\n",
    "\n",
    "import threading\n",
    "\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100_000):\n",
    "        with lock:          # only one thread can enter this block at a time\n",
    "            counter += 1\n",
    "\n",
    "t1 = threading.Thread(target=increment)\n",
    "t2 = threading.Thread(target=increment)\n",
    "\n",
    "t1.start(); t2.start()\n",
    "t1.join();  t2.join()\n",
    "\n",
    "print(\"Counter:\", counter)\n",
    "# OUTPUT: Counter: 200000\n",
    "\n",
    "# Locks protect shared mutable state\n",
    "# Always use a lock when:\n",
    "# multiple threads write to shared data\n",
    "# with lock: is the safest pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2bff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Avoiding deadlocks\n",
    "# A deadlock happens when:\n",
    "# thread A holds lock1 and waits for lock2\n",
    "# thread B holds lock2 and waits for lock1\n",
    "# Both wait forever.\n",
    "\n",
    "# Rule: If you must use multiple locks, always acquire them in the same order everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e2f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread coordination tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb018562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: waiting for signal\n",
      "Main: sending signal\n",
      "Worker: got signal, starting work\n"
     ]
    }
   ],
   "source": [
    "# 9) Event (one thread signals another)\n",
    "# Use Event when one thread should wait until another thread signals “go”.\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "ready = threading.Event()\n",
    "\n",
    "def worker():\n",
    "    print(\"Worker: waiting for signal\")\n",
    "    ready.wait()  # blocks until event is set\n",
    "    print(\"Worker: got signal, starting work\")\n",
    "\n",
    "t = threading.Thread(target=worker)\n",
    "t.start()\n",
    "\n",
    "time.sleep(1)\n",
    "print(\"Main: sending signal\")\n",
    "ready.set()\n",
    "\n",
    "t.join()\n",
    "\n",
    "# OUTPUT:\n",
    "# Worker: waiting for signal\n",
    "# Main: sending signal\n",
    "# Worker: got signal, starting work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c48548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:Start: 1\n",
      " 0\n",
      "End: 1\n",
      "Start: 2\n",
      "End: 0\n",
      "Start: 3\n",
      "End:End: 3\n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "# 10) Semaphore (limit how many threads can run a section)\n",
    "# Useful when you want “max N threads doing this at once”.\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "sem = threading.Semaphore(2)  # allow only 2 threads at a time\n",
    "\n",
    "def limited_work(i):\n",
    "    with sem:\n",
    "        print(\"Start:\", i)\n",
    "        time.sleep(1)\n",
    "        print(\"End:\", i)\n",
    "\n",
    "threads = [threading.Thread(target=limited_work, args=(i,)) for i in range(4)]\n",
    "for t in threads: t.start()\n",
    "for t in threads: t.join()\n",
    "\n",
    "# OUTPUT (pattern: only 2 starts appear before 2 ends):\n",
    "# Start: 0\n",
    "# Start: 1\n",
    "# End: 0\n",
    "# End: 1\n",
    "# Start: 2\n",
    "# Start: 3\n",
    "# End: 2\n",
    "# End: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da2d2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced:Consumed: A\n",
      " A\n",
      "Produced: B\n",
      "Produced: C\n",
      "Consumed: B\n",
      "Consumed: C\n",
      "Consumer: stopping\n"
     ]
    }
   ],
   "source": [
    "# 11) Queue (best for producer-consumer patterns)\n",
    "# Queue is thread-safe and the cleanest way to pass work/results.\n",
    "\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "def producer():\n",
    "    for item in [\"A\", \"B\", \"C\"]:\n",
    "        q.put(item)                 # add work\n",
    "        print(\"Produced:\", item)\n",
    "    q.put(None)                     # special marker to stop consumer\n",
    "\n",
    "def consumer():\n",
    "    while True:\n",
    "        item = q.get()              # take work (waits if empty)\n",
    "        if item is None:\n",
    "            print(\"Consumer: stopping\")\n",
    "            break\n",
    "        print(\"Consumed:\", item)\n",
    "\n",
    "t1 = threading.Thread(target=producer)\n",
    "t2 = threading.Thread(target=consumer)\n",
    "\n",
    "t1.start(); t2.start()\n",
    "t1.join();  t2.join()\n",
    "\n",
    "# OUTPUT:\n",
    "# Produced: A\n",
    "# Produced: B\n",
    "# Produced: C\n",
    "# Consumed: A\n",
    "# Consumed: B\n",
    "# Consumed: C\n",
    "# Consumer: stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3fa83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efc3f5db",
   "metadata": {},
   "source": [
    "# Understanding Threads and the GIL\n",
    "\n",
    "## What Is a Thread?\n",
    "\n",
    "A **thread** is a unit of execution within a process.\n",
    "\n",
    "* A **process** owns memory and resources\n",
    "* A **thread** shares the process memory\n",
    "* Multiple threads can exist inside a single process\n",
    "\n",
    "In Python:\n",
    "\n",
    "* All threads within a process share the same memory space\n",
    "* Threads run concurrently, not independently\n",
    "\n",
    "This shared-memory model makes threads lightweight, but it also introduces coordination challenges.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Threads Are Used\n",
    "\n",
    "Threads are commonly used to:\n",
    "\n",
    "* Handle multiple tasks concurrently\n",
    "* Keep applications responsive\n",
    "* Overlap waiting operations (I/O)\n",
    "* Simplify designs that require shared state\n",
    "\n",
    "Threads are especially useful when tasks spend time **waiting**, not computing.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating Threads in Python\n",
    "\n",
    "Python provides the `threading` module for working with threads.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task():\n",
    "    print(\"Task running\")\n",
    "\n",
    "t = threading.Thread(target=task)\n",
    "t.start()\n",
    "t.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `Thread` creates a new thread\n",
    "* `start()` begins execution in a separate thread\n",
    "* `join()` waits for the thread to finish\n",
    "\n",
    "At this point, the program has executed code concurrently, even if briefly.\n",
    "\n",
    "---\n",
    "\n",
    "## Multiple Threads Running Together\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task(name):\n",
    "    print(f\"Task {name} running\")\n",
    "\n",
    "threads = []\n",
    "\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=task, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* All threads share the same process\n",
    "* Execution order is not guaranteed\n",
    "* Output order may vary between runs\n",
    "\n",
    "This nondeterminism is normal in multithreaded programs.\n",
    "\n",
    "---\n",
    "\n",
    "## Shared Memory in Threads\n",
    "\n",
    "Threads share:\n",
    "\n",
    "* Global variables\n",
    "* Heap objects\n",
    "* Module-level state\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "All threads see and modify the same `counter`.\n",
    "\n",
    "This sharing is powerful but dangerous without proper synchronization.\n",
    "\n",
    "---\n",
    "\n",
    "## Race Conditions (Conceptual)\n",
    "\n",
    "A **race condition** occurs when:\n",
    "\n",
    "* Multiple threads access shared data\n",
    "* At least one thread modifies the data\n",
    "* Execution order affects the result\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100_000):\n",
    "        counter += 1\n",
    "```\n",
    "\n",
    "Running this in multiple threads may produce incorrect results due to overlapping operations.\n",
    "\n",
    "This problem exists even before considering the GIL.\n",
    "\n",
    "---\n",
    "\n",
    "## Where the GIL Fits In\n",
    "\n",
    "The Global Interpreter Lock (GIL) controls **execution of Python bytecode**, not thread creation.\n",
    "\n",
    "Key points already established earlier:\n",
    "\n",
    "* Only one thread executes Python bytecode at a time\n",
    "* Threads still exist and are scheduled\n",
    "* The GIL protects Python’s internal memory management\n",
    "\n",
    "Now the focus is on **how this affects real threaded programs**.\n",
    "\n",
    "---\n",
    "\n",
    "## Threads With CPU-Bound Work\n",
    "\n",
    "CPU-bound work is computation-heavy and spends most of its time executing Python code.\n",
    "\n",
    "```python\n",
    "def cpu_task():\n",
    "    total = 0\n",
    "    for i in range(10_000_000):\n",
    "        total += i\n",
    "```\n",
    "\n",
    "If multiple threads run this function:\n",
    "\n",
    "* Threads compete for the GIL\n",
    "* Only one thread makes progress at a time\n",
    "* CPU cores are not fully utilized\n",
    "\n",
    "Threads do not provide speedup for CPU-bound Python code.\n",
    "\n",
    "---\n",
    "\n",
    "## Threads With I/O-Bound Work\n",
    "\n",
    "I/O-bound work spends time waiting:\n",
    "\n",
    "* Network requests\n",
    "* Disk reads\n",
    "* Sleeping\n",
    "* External APIs\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "def io_task():\n",
    "    time.sleep(2)\n",
    "```\n",
    "\n",
    "During I/O:\n",
    "\n",
    "* The thread releases the GIL\n",
    "* Another thread can run\n",
    "* Waiting time overlaps\n",
    "\n",
    "This is where threads are effective.\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: CPU-Bound Threads\n",
    "\n",
    "This code must be saved as `thread_cpu_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python thread_cpu_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def cpu_task():\n",
    "    count = 0\n",
    "    for _ in range(10_000_000):\n",
    "        count += 1\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(target=cpu_task),\n",
    "    threading.Thread(target=cpu_task)\n",
    "]\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Time taken:\", time.time() - start)\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Execution time is close to single-thread execution\n",
    "* CPU cores are not effectively used\n",
    "* The GIL limits parallel execution\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: I/O-Bound Threads\n",
    "\n",
    "This code must be saved as `thread_io_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python thread_io_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def io_task():\n",
    "    time.sleep(2)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    t = threading.Thread(target=io_task)\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Time taken:\", time.time() - start)\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Total time is close to 2 seconds\n",
    "* Threads overlap waiting time\n",
    "* Threading improves throughput for I/O-bound tasks\n",
    "\n",
    "---\n",
    "\n",
    "## Thread Scheduling and Context Switching\n",
    "\n",
    "Python switches between threads:\n",
    "\n",
    "* After a fixed number of bytecode instructions\n",
    "* When a thread performs blocking I/O\n",
    "\n",
    "This switching:\n",
    "\n",
    "* Provides fairness\n",
    "* Keeps applications responsive\n",
    "* Does not guarantee execution order\n",
    "\n",
    "Developers should never rely on a specific thread order.\n",
    "\n",
    "---\n",
    "\n",
    "## Common Misconceptions About Threads and the GIL\n",
    "\n",
    "* Threads do not run Python code in parallel on multiple cores\n",
    "* Threads are not useless; they are effective for I/O\n",
    "* The GIL does not prevent concurrency, only CPU parallelism\n",
    "* Removing the GIL would require a fundamentally different memory model\n",
    "\n",
    "Understanding these points prevents incorrect architectural decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## When Threads Are the Right Choice\n",
    "\n",
    "Threads are suitable when:\n",
    "\n",
    "* Tasks are I/O-bound\n",
    "* Shared memory simplifies design\n",
    "* Latency matters more than throughput\n",
    "* External systems dominate execution time\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Web request handling\n",
    "* Network clients\n",
    "* Log ingestion\n",
    "* API orchestration\n",
    "\n",
    "---\n",
    "\n",
    "## When Threads Are the Wrong Choice\n",
    "\n",
    "Threads should be avoided when:\n",
    "\n",
    "* Work is CPU-heavy\n",
    "* Computation dominates execution\n",
    "* True parallelism is required\n",
    "\n",
    "In these cases:\n",
    "\n",
    "* Multiprocessing\n",
    "* Native extensions\n",
    "* Vectorized libraries\n",
    "  are more appropriate.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Thread Behavior Analysis\n",
    "\n",
    "Create two Python scripts.\n",
    "\n",
    "Script 1:\n",
    "\n",
    "* Use multiple threads to perform a CPU-heavy loop\n",
    "* Measure execution time\n",
    "\n",
    "Script 2:\n",
    "\n",
    "* Use multiple threads to perform a blocking operation (sleep or I/O)\n",
    "* Measure execution time\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Observe how the GIL affects CPU-bound threads\n",
    "* Observe how threads overlap I/O-bound work\n",
    "* Decide when threading is appropriate\n",
    "\n",
    "The results should clearly show different behavior depending on workload type.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c6fe6a1",
   "metadata": {},
   "source": [
    "# `threading` Module Essentials\n",
    "\n",
    "## Purpose of the `threading` Module\n",
    "\n",
    "The `threading` module provides **high-level tools** for working with threads in Python. It allows programs to:\n",
    "\n",
    "* Run multiple tasks concurrently\n",
    "* Share memory between threads\n",
    "* Coordinate execution safely\n",
    "* Manage thread lifecycle explicitly\n",
    "\n",
    "Unlike low-level thread APIs, `threading` is designed to be:\n",
    "\n",
    "* Readable\n",
    "* Portable\n",
    "* Safer by default\n",
    "\n",
    "Understanding these essentials is required before working with synchronization and thread safety.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating and Starting a Thread\n",
    "\n",
    "The most basic unit in the `threading` module is the `Thread` class.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task():\n",
    "    print(\"Task running\")\n",
    "\n",
    "t = threading.Thread(target=task)\n",
    "t.start()\n",
    "t.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `target` is the callable executed by the thread\n",
    "* `start()` schedules the thread for execution\n",
    "* `join()` blocks until the thread finishes\n",
    "\n",
    "A thread does nothing until `start()` is called.\n",
    "\n",
    "---\n",
    "\n",
    "## Passing Arguments to Threads\n",
    "\n",
    "Threads often need input data.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task(name):\n",
    "    print(f\"Task {name} running\")\n",
    "\n",
    "t = threading.Thread(target=task, args=(\"A\",))\n",
    "t.start()\n",
    "t.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `args` is a tuple of positional arguments\n",
    "* Keyword arguments can be passed using `kwargs`\n",
    "* The function signature remains unchanged\n",
    "\n",
    "---\n",
    "\n",
    "## Running Multiple Threads\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def worker(i):\n",
    "    print(f\"Worker {i} started\")\n",
    "\n",
    "threads = []\n",
    "\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Threads run concurrently\n",
    "* Output order is not guaranteed\n",
    "* All threads complete before the program exits\n",
    "\n",
    "Thread execution order should never be relied upon.\n",
    "\n",
    "---\n",
    "\n",
    "## Thread Naming\n",
    "\n",
    "Threads can be given names to improve debugging and logging.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task():\n",
    "    print(threading.current_thread().name)\n",
    "\n",
    "t = threading.Thread(target=task, name=\"WorkerThread\")\n",
    "t.start()\n",
    "t.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Each thread has a name\n",
    "* Names help identify threads in logs and debuggers\n",
    "* Default names are auto-generated if not specified\n",
    "\n",
    "---\n",
    "\n",
    "## Getting the Current Thread\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task():\n",
    "    current = threading.current_thread()\n",
    "    print(current.name, current.ident)\n",
    "\n",
    "t = threading.Thread(target=task)\n",
    "t.start()\n",
    "t.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `current_thread()` returns the running thread object\n",
    "* `ident` is a unique thread identifier\n",
    "* Useful for diagnostics and logging\n",
    "\n",
    "---\n",
    "\n",
    "## Daemon vs Non-Daemon Threads\n",
    "\n",
    "Threads can be either **daemon** or **non-daemon**.\n",
    "\n",
    "* Non-daemon threads keep the program alive\n",
    "* Daemon threads do not block program exit\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def background_task():\n",
    "    while True:\n",
    "        print(\"Running in background\")\n",
    "        time.sleep(1)\n",
    "\n",
    "t = threading.Thread(target=background_task, daemon=True)\n",
    "t.start()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The program exits even if the daemon thread is still running\n",
    "* Daemon threads are suitable for background helpers\n",
    "* Important work should not be done in daemon threads\n",
    "\n",
    "---\n",
    "\n",
    "## Checking Thread State\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def task():\n",
    "    time.sleep(1)\n",
    "\n",
    "t = threading.Thread(target=task)\n",
    "t.start()\n",
    "\n",
    "print(t.is_alive())\n",
    "t.join()\n",
    "print(t.is_alive())\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `is_alive()` checks if the thread is still running\n",
    "* Useful for monitoring thread lifecycle\n",
    "\n",
    "---\n",
    "\n",
    "## Thread Lifecycle Summary\n",
    "\n",
    "A thread typically goes through these states:\n",
    "\n",
    "* Created\n",
    "* Started\n",
    "* Running\n",
    "* Finished\n",
    "\n",
    "Once a thread finishes:\n",
    "\n",
    "* It cannot be restarted\n",
    "* A new `Thread` object must be created\n",
    "\n",
    "---\n",
    "\n",
    "## Common Mistake: Forgetting `join()`\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task():\n",
    "    print(\"Task running\")\n",
    "\n",
    "threading.Thread(target=task).start()\n",
    "print(\"Main thread finished\")\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The main thread may exit before the worker finishes\n",
    "* Results may appear incomplete or inconsistent\n",
    "* `join()` ensures predictable shutdown\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: Thread Lifecycle\n",
    "\n",
    "This code must be saved as `thread_lifecycle_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python thread_lifecycle_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def worker():\n",
    "    print(\"Worker started\")\n",
    "    time.sleep(2)\n",
    "    print(\"Worker finished\")\n",
    "\n",
    "t = threading.Thread(target=worker, name=\"Worker-1\")\n",
    "print(\"Thread created\")\n",
    "\n",
    "t.start()\n",
    "print(\"Thread started\")\n",
    "\n",
    "t.join()\n",
    "print(\"Thread joined, program exiting\")\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Thread creation does not start execution\n",
    "* `start()` triggers execution\n",
    "* `join()` ensures completion before exit\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Guidelines for Using Threads\n",
    "\n",
    "Threads should be:\n",
    "\n",
    "* Short-lived when possible\n",
    "* Clearly named\n",
    "* Properly joined\n",
    "* Used primarily for I/O-bound tasks\n",
    "\n",
    "Avoid:\n",
    "\n",
    "* Long-running daemon threads doing critical work\n",
    "* Relying on execution order\n",
    "* Modifying shared data without synchronization\n",
    "\n",
    "Synchronization mechanisms will be covered next.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Basic Thread Management\n",
    "\n",
    "Create a Python script that:\n",
    "\n",
    "* Starts three threads\n",
    "* Each thread prints its name and sleeps for a different duration\n",
    "* The main thread waits for all threads to complete\n",
    "* Prints a final message after all threads finish\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Practice thread creation and lifecycle management\n",
    "* Observe nondeterministic execution order\n",
    "* Use `join()` correctly\n",
    "\n",
    "The output should demonstrate that:\n",
    "\n",
    "* Threads run concurrently\n",
    "* The main thread waits for all workers\n",
    "* Program exits cleanly\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a99c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c3e06c",
   "metadata": {},
   "source": [
    "# Synchronization Using Locks, Events, Semaphores, and Queues\n",
    "\n",
    "## Why Synchronization Is Needed\n",
    "\n",
    "When multiple threads run at the same time, they often **share data**. Shared data can be:\n",
    "\n",
    "* Variables\n",
    "* Lists or dictionaries\n",
    "* Files\n",
    "* Network connections\n",
    "* Any object in memory\n",
    "\n",
    "Without coordination, multiple threads may:\n",
    "\n",
    "* Read and write data at the same time\n",
    "* Interfere with each other’s operations\n",
    "* Produce incorrect or inconsistent results\n",
    "\n",
    "**Synchronization** is the set of techniques used to control how threads access shared resources so that execution remains correct and predictable.\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Problem: Race Conditions\n",
    "\n",
    "A **race condition** occurs when:\n",
    "\n",
    "* Multiple threads access shared data\n",
    "* At least one thread modifies the data\n",
    "* The final result depends on the execution order\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "If multiple threads run `increment()` at the same time:\n",
    "\n",
    "* The operations can overlap\n",
    "* Some increments may be lost\n",
    "* The final value may be incorrect\n",
    "\n",
    "This happens even though each line of code looks simple.\n",
    "\n",
    "---\n",
    "\n",
    "## Why the GIL Does Not Solve This Problem\n",
    "\n",
    "Even with the Global Interpreter Lock:\n",
    "\n",
    "* Threads can switch between bytecode instructions\n",
    "* Operations like `counter += 1` are not atomic\n",
    "* Partial updates can still interleave\n",
    "\n",
    "Therefore:\n",
    "\n",
    "* The GIL protects Python’s internals\n",
    "* It does not protect your application data\n",
    "\n",
    "Synchronization is still required.\n",
    "\n",
    "---\n",
    "\n",
    "## Lock: The Most Basic Synchronization Tool\n",
    "\n",
    "A **Lock** ensures that only **one thread at a time** can execute a specific section of code.\n",
    "\n",
    "Locks are used to protect **critical sections**, which are code blocks that access shared data.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating and Using a Lock\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    with lock:\n",
    "        counter += 1\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* A thread must acquire the lock before entering the `with` block\n",
    "* Other threads wait until the lock is released\n",
    "* The lock is released automatically when the block exits\n",
    "\n",
    "This guarantees correctness.\n",
    "\n",
    "---\n",
    "\n",
    "## Lock Behavior in Practice\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100_000):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(target=increment),\n",
    "    threading.Thread(target=increment)\n",
    "]\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(counter)\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* The final value is correct\n",
    "* Performance is slower than unsynchronized code\n",
    "* Correctness is more important than speed\n",
    "\n",
    "---\n",
    "\n",
    "## Event: Signaling Between Threads\n",
    "\n",
    "An **Event** is used for **communication**, not protection.\n",
    "\n",
    "It allows:\n",
    "\n",
    "* One thread to signal something has happened\n",
    "* Other threads to wait until the signal is set\n",
    "\n",
    "An Event has two states:\n",
    "\n",
    "* Unset (False)\n",
    "* Set (True)\n",
    "\n",
    "---\n",
    "\n",
    "## Using an Event\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "event = threading.Event()\n",
    "\n",
    "def wait_for_event():\n",
    "    print(\"Waiting for event\")\n",
    "    event.wait()\n",
    "    print(\"Event received\")\n",
    "\n",
    "def trigger_event():\n",
    "    time.sleep(2)\n",
    "    event.set()\n",
    "\n",
    "threading.Thread(target=wait_for_event).start()\n",
    "threading.Thread(target=trigger_event).start()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `wait()` blocks until the event is set\n",
    "* `set()` wakes all waiting threads\n",
    "* Useful for coordination, not mutual exclusion\n",
    "\n",
    "---\n",
    "\n",
    "## Semaphore: Controlling Access Count\n",
    "\n",
    "A **Semaphore** controls how many threads can access a resource **at the same time**.\n",
    "\n",
    "Unlike a Lock:\n",
    "\n",
    "* A Lock allows only one thread\n",
    "* A Semaphore allows a fixed number of threads\n",
    "\n",
    "---\n",
    "\n",
    "## Using a Semaphore\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "semaphore = threading.Semaphore(2)\n",
    "\n",
    "def access_resource(name):\n",
    "    with semaphore:\n",
    "        print(f\"{name} accessing resource\")\n",
    "        time.sleep(1)\n",
    "        print(f\"{name} leaving resource\")\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(target=access_resource, args=(f\"Thread-{i}\",))\n",
    "    for i in range(4)\n",
    "]\n",
    "\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Only two threads access the resource at once\n",
    "* Others wait until a slot is available\n",
    "* Useful for connection pools and rate limits\n",
    "\n",
    "---\n",
    "\n",
    "## Queue: Thread-Safe Data Exchange\n",
    "\n",
    "A **Queue** is a thread-safe data structure designed for **producer-consumer** patterns.\n",
    "\n",
    "Unlike lists:\n",
    "\n",
    "* Queues handle synchronization internally\n",
    "* No manual locks are needed\n",
    "* Threads can safely add and remove items\n",
    "\n",
    "---\n",
    "\n",
    "## Basic Queue Usage\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "def producer():\n",
    "    for i in range(5):\n",
    "        q.put(i)\n",
    "        print(f\"Produced {i}\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "def consumer():\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        print(f\"Consumed {item}\")\n",
    "        q.task_done()\n",
    "\n",
    "threading.Thread(target=producer).start()\n",
    "threading.Thread(target=consumer, daemon=True).start()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `put()` adds an item safely\n",
    "* `get()` removes an item safely\n",
    "* `task_done()` signals completion\n",
    "* Queues handle locking internally\n",
    "\n",
    "---\n",
    "\n",
    "## Why Queues Are Preferred Over Manual Locks\n",
    "\n",
    "Queues:\n",
    "\n",
    "* Reduce complexity\n",
    "* Prevent common synchronization bugs\n",
    "* Scale well with multiple producers and consumers\n",
    "* Encourage clean architectural patterns\n",
    "\n",
    "In most cases, using a Queue is safer than sharing a list with a Lock.\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: Producer-Consumer Pattern\n",
    "\n",
    "This code must be saved as `queue_producer_consumer.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python queue_producer_consumer.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "def producer():\n",
    "    for i in range(3):\n",
    "        print(f\"Producing {i}\")\n",
    "        q.put(i)\n",
    "        time.sleep(1)\n",
    "    q.put(None)\n",
    "\n",
    "def consumer():\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        print(f\"Consuming {item}\")\n",
    "        q.task_done()\n",
    "\n",
    "t1 = threading.Thread(target=producer)\n",
    "t2 = threading.Thread(target=consumer)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Choosing the Right Synchronization Tool\n",
    "\n",
    "| Tool      | Purpose                            |\n",
    "| --------- | ---------------------------------- |\n",
    "| Lock      | Protect shared data                |\n",
    "| Event     | Signal between threads             |\n",
    "| Semaphore | Limit concurrent access            |\n",
    "| Queue     | Safe data exchange between threads |\n",
    "\n",
    "Choosing the correct tool simplifies design and reduces bugs.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Synchronization in Practice\n",
    "\n",
    "Create a Python script that:\n",
    "\n",
    "* Uses a Lock to protect a shared counter\n",
    "* Uses an Event to signal worker threads to start\n",
    "* Uses a Semaphore to limit concurrent execution\n",
    "* Uses a Queue to pass tasks between threads\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Practice each synchronization primitive\n",
    "* Understand their different roles\n",
    "* Observe safe, predictable behavior\n",
    "\n",
    "The solution should demonstrate:\n",
    "\n",
    "* Correct data updates\n",
    "* Proper coordination\n",
    "* No race conditions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cfe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b60f45e",
   "metadata": {},
   "source": [
    "# Thread-Safe Data Access and Deadlock Avoidance\n",
    "\n",
    "## What Does “Thread-Safe” Mean?\n",
    "\n",
    "A piece of code is **thread-safe** if it behaves correctly when accessed by multiple threads at the same time.\n",
    "\n",
    "Correct behavior means:\n",
    "\n",
    "* Data remains consistent\n",
    "* No updates are lost\n",
    "* No unexpected crashes occur\n",
    "* Results do not depend on execution order\n",
    "\n",
    "Thread safety is not automatic. It must be **designed deliberately**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Thread Safety Is Necessary\n",
    "\n",
    "Threads share memory. This means:\n",
    "\n",
    "* Multiple threads can read the same variable\n",
    "* Multiple threads can modify the same object\n",
    "* Operations can interleave unpredictably\n",
    "\n",
    "Without thread safety:\n",
    "\n",
    "* Data corruption can occur\n",
    "* Bugs appear randomly\n",
    "* Problems are difficult to reproduce\n",
    "\n",
    "Thread safety protects **shared state**.\n",
    "\n",
    "---\n",
    "\n",
    "## Identifying Shared Data\n",
    "\n",
    "Shared data includes:\n",
    "\n",
    "* Global variables\n",
    "* Objects referenced by multiple threads\n",
    "* Class attributes\n",
    "* Data structures passed between threads\n",
    "\n",
    "Local variables inside a function are **not shared** unless explicitly referenced elsewhere.\n",
    "\n",
    "Understanding what is shared is the first step toward safety.\n",
    "\n",
    "---\n",
    "\n",
    "## Example of Unsafe Data Access\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "If multiple threads call `increment()`:\n",
    "\n",
    "* `counter += 1` is broken into multiple steps\n",
    "* Threads can interrupt each other\n",
    "* The final result may be incorrect\n",
    "\n",
    "This is not thread-safe.\n",
    "\n",
    "---\n",
    "\n",
    "## Making Data Access Thread-Safe with Locks\n",
    "\n",
    "The simplest way to make code thread-safe is to use a **Lock**.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    with lock:\n",
    "        counter += 1\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Only one thread enters the critical section\n",
    "* Other threads wait\n",
    "* Data integrity is preserved\n",
    "\n",
    "This pattern is the foundation of thread-safe design.\n",
    "\n",
    "---\n",
    "\n",
    "## Critical Sections\n",
    "\n",
    "A **critical section** is:\n",
    "\n",
    "* The smallest piece of code that accesses shared data\n",
    "* The section that must not run concurrently\n",
    "\n",
    "Good practice:\n",
    "\n",
    "* Keep critical sections short\n",
    "* Lock only what is necessary\n",
    "* Avoid unnecessary blocking\n",
    "\n",
    "This improves both safety and performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Thread-Safe Data Structures\n",
    "\n",
    "Some Python data structures are **partially thread-safe** for simple operations.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* `queue.Queue` (fully thread-safe)\n",
    "* `collections.deque` (thread-safe appends and pops)\n",
    "\n",
    "However:\n",
    "\n",
    "* Compound operations are not automatically safe\n",
    "* Assumptions about safety can lead to bugs\n",
    "\n",
    "Explicit synchronization is still required for complex logic.\n",
    "\n",
    "---\n",
    "\n",
    "## Avoiding Shared State When Possible\n",
    "\n",
    "The safest thread-safe code is code that:\n",
    "\n",
    "* Avoids shared mutable state\n",
    "* Uses message passing instead of shared variables\n",
    "* Communicates through Queues\n",
    "\n",
    "This approach reduces the need for locks and simplifies reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is a Deadlock?\n",
    "\n",
    "A **deadlock** occurs when:\n",
    "\n",
    "* Two or more threads are waiting for each other\n",
    "* Each thread holds a resource the other needs\n",
    "* No thread can proceed\n",
    "\n",
    "The program stops making progress indefinitely.\n",
    "\n",
    "---\n",
    "\n",
    "## Simple Deadlock Example\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "lock_a = threading.Lock()\n",
    "lock_b = threading.Lock()\n",
    "\n",
    "def task_one():\n",
    "    with lock_a:\n",
    "        time.sleep(1)\n",
    "        with lock_b:\n",
    "            print(\"Task one complete\")\n",
    "\n",
    "def task_two():\n",
    "    with lock_b:\n",
    "        time.sleep(1)\n",
    "        with lock_a:\n",
    "            print(\"Task two complete\")\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `task_one` holds `lock_a` and waits for `lock_b`\n",
    "* `task_two` holds `lock_b` and waits for `lock_a`\n",
    "* Both threads are blocked forever\n",
    "\n",
    "This is a deadlock.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Deadlocks Are Dangerous\n",
    "\n",
    "Deadlocks:\n",
    "\n",
    "* Do not raise errors\n",
    "* Do not crash the program\n",
    "* Appear as “hung” applications\n",
    "* Are difficult to debug\n",
    "\n",
    "Preventing deadlocks is easier than fixing them.\n",
    "\n",
    "---\n",
    "\n",
    "## Deadlock Avoidance Rule #1: Lock Ordering\n",
    "\n",
    "Always acquire multiple locks in the **same order**.\n",
    "\n",
    "```python\n",
    "def safe_task():\n",
    "    with lock_a:\n",
    "        with lock_b:\n",
    "            print(\"Safe execution\")\n",
    "```\n",
    "\n",
    "If all threads follow the same order:\n",
    "\n",
    "* Circular waiting cannot occur\n",
    "* Deadlocks are avoided\n",
    "\n",
    "This is the most important deadlock prevention technique.\n",
    "\n",
    "---\n",
    "\n",
    "## Deadlock Avoidance Rule #2: Minimize Lock Scope\n",
    "\n",
    "Holding locks longer than necessary increases deadlock risk.\n",
    "\n",
    "Good practice:\n",
    "\n",
    "* Acquire lock as late as possible\n",
    "* Release lock as early as possible\n",
    "* Avoid long operations inside locks\n",
    "\n",
    "This reduces contention and waiting.\n",
    "\n",
    "---\n",
    "\n",
    "## Deadlock Avoidance Rule #3: Avoid Nested Locks When Possible\n",
    "\n",
    "Nested locks increase complexity.\n",
    "\n",
    "Instead of:\n",
    "\n",
    "```python\n",
    "with lock_a:\n",
    "    with lock_b:\n",
    "        ...\n",
    "```\n",
    "\n",
    "Consider:\n",
    "\n",
    "* Merging critical sections\n",
    "* Using a single lock\n",
    "* Redesigning data flow\n",
    "\n",
    "Simpler locking leads to safer code.\n",
    "\n",
    "---\n",
    "\n",
    "## Deadlock Avoidance Rule #4: Use Timeouts\n",
    "\n",
    "Locks can be acquired with timeouts.\n",
    "\n",
    "```python\n",
    "acquired = lock.acquire(timeout=1)\n",
    "if acquired:\n",
    "    try:\n",
    "        print(\"Lock acquired\")\n",
    "    finally:\n",
    "        lock.release()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Threads do not wait forever\n",
    "* Timeouts allow recovery logic\n",
    "* Useful in high-availability systems\n",
    "\n",
    "---\n",
    "\n",
    "## Using Context Managers for Safety\n",
    "\n",
    "Always prefer `with lock:` syntax.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Automatic release\n",
    "* Exception-safe behavior\n",
    "* Clear and readable code\n",
    "\n",
    "This reduces mistakes that lead to deadlocks.\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: Deadlock and Safe Access\n",
    "\n",
    "This code must be saved as `deadlock_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python deadlock_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "lock_a = threading.Lock()\n",
    "lock_b = threading.Lock()\n",
    "\n",
    "def safe_task():\n",
    "    with lock_a:\n",
    "        time.sleep(0.5)\n",
    "        with lock_b:\n",
    "            print(\"Safe task completed\")\n",
    "\n",
    "t1 = threading.Thread(target=safe_task)\n",
    "t2 = threading.Thread(target=safe_task)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Both threads complete successfully\n",
    "* Lock ordering prevents deadlock\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Best Practices\n",
    "\n",
    "* Protect shared data with locks\n",
    "* Prefer queues over shared state\n",
    "* Keep critical sections small\n",
    "* Follow consistent lock ordering\n",
    "* Avoid unnecessary nested locks\n",
    "* Design for simplicity\n",
    "\n",
    "Thread-safe code is easier to reason about when structure is clean.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Safe Access and Deadlock Prevention\n",
    "\n",
    "Create a Python script that:\n",
    "\n",
    "* Uses two shared resources\n",
    "* Protects each resource with a lock\n",
    "* Ensures all threads acquire locks in the same order\n",
    "* Demonstrates safe execution without deadlock\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Practice identifying critical sections\n",
    "* Apply deadlock avoidance rules\n",
    "* Observe predictable behavior\n",
    "\n",
    "The solution should clearly show that:\n",
    "\n",
    "* Data remains consistent\n",
    "* Threads do not block indefinitely\n",
    "* Execution completes successfully\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224cc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90de915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 4B: Multi-processing\n",
    "# • Using the multiprocessing module\n",
    "# • Process Pools and shared memory objects\n",
    "# • Inter-process communication (IPC) and data serialization\n",
    "# • Best use cases for processes vs threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c7d7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Multiprocessing?\n",
    "# Multiprocessing means running your work using multiple processes (separate Python programs) at the same time.\n",
    "# A process is a running program with its own memory\n",
    "# Each process can run on a different CPU core\n",
    "# This gives true parallel execution for CPU-heavy work\n",
    "\n",
    "# Why do we need multiprocessing?\n",
    "# Because Python threads don’t speed up CPU-bound code well in CPython due to the GIL.\n",
    "# Multiprocessing solves this by using separate processes, each with its own GIL.\n",
    "\n",
    "# Use multiprocessing when the work is:\n",
    "# - heavy calculations\n",
    "# - large loops\n",
    "# - data processing\n",
    "# - CPU-bound tasks (compression, encryption, simulations)\n",
    "\n",
    "# Key Terms:\n",
    "# 1. Process: independent worker program\n",
    "# 2. Main process: your original Python program\n",
    "# 3. Child process: a new process created by main\n",
    "# 4. IPC (Inter-Process Communication): ways to share data between processes (Queue, Pipe, shared memory)\n",
    "# 5. Pickling: Python converts objects to bytes to send them to another process (important limitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92cb3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The simplest multiprocessing example (start + join)\n",
    "\n",
    "# import multiprocessing\n",
    "# import time\n",
    "\n",
    "# def task():\n",
    "#     print(\"Child process: starting work\")\n",
    "#     time.sleep(2)  # simulate work\n",
    "#     print(\"Child process: finished work\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # This guard is required on Windows/macOS (spawn mode)\n",
    "#     start = time.time()\n",
    "\n",
    "#     p = multiprocessing.Process(target=task)  # create a new process to run task()\n",
    "#     p.start()                                 # start the child process\n",
    "#     p.join()                                  # wait for child process to finish\n",
    "\n",
    "#     end = time.time()\n",
    "#     print(\"Time taken:\", end - start)\n",
    "\n",
    "# # OUTPUT (approx):\n",
    "# # Child process: starting work\n",
    "# # Child process: finished work\n",
    "# # Time taken: ~2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b680ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Why multiprocessing helps CPU-bound work (real benefit)\n",
    "\n",
    "# CPU-heavy function\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cpu_task(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "# But processes can’t directly “return” like normal calls, so we use a Queue to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Queue to collect results\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cpu_task(n, out_q):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    out_q.put(total)  # send result back to main process\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "\n",
    "    q = multiprocessing.Queue()  # process-safe queue\n",
    "\n",
    "    p1 = multiprocessing.Process(target=cpu_task, args=(50_000_000, q))\n",
    "    p2 = multiprocessing.Process(target=cpu_task, args=(50_000_000, q))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    r1 = q.get()  # get result from process 1\n",
    "    r2 = q.get()  # get result from process 2\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Two results received:\", r1, r2)\n",
    "    print(\"Time taken:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easiest high-level multiprocessing tool: Pool\n",
    "\n",
    "# When you have many inputs and want to run the same function on them, use Pool.\n",
    "\n",
    "# C) Pool.map()\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "def square(x):\n",
    "    # os.getpid() shows which process is running this\n",
    "    print(\"Squaring\", x, \"in process\", os.getpid())\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "    with multiprocessing.Pool(processes=2) as pool:\n",
    "        results = pool.map(square, numbers)  # run square() on each item in parallel\n",
    "\n",
    "    print(\"Results:\", results)\n",
    "\n",
    "# OUTPUT (pid will differ):\n",
    "# Squaring 1 in process 12345\n",
    "# Squaring 2 in process 12346\n",
    "# Squaring 3 in process 12345\n",
    "# Squaring 4 in process 12346\n",
    "# Squaring 5 in process 12345\n",
    "# Results: [1, 4, 9, 16, 25]\n",
    "\n",
    "\n",
    "# Pool creates a fixed number of worker processes\n",
    "# map distributes tasks across workers\n",
    "# Returns results in the same order as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing data to processes\n",
    "\n",
    "# D) Why normal variables don’t update across processes\n",
    "# Processes do not share memory. Example:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    counter += 1  # this changes counter only inside the child process\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = multiprocessing.Process(target=increment)\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(\"Counter in main process:\", counter)\n",
    "    # OUTPUT: Counter in main process: 0\n",
    "\n",
    "\n",
    "# global ≠ shared across processes\n",
    "# Changes in a child process never affect the parent unless you explicitly share data\n",
    "\n",
    "# To share data between processes, use:\n",
    "# multiprocessing.Value\n",
    "# multiprocessing.Array\n",
    "# multiprocessing.Queue\n",
    "# multiprocessing.Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharing data properly between processes\n",
    "\n",
    "# E) Use multiprocessing.Value for simple shared numbers\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def increment(shared_counter):\n",
    "    # shared_counter is a special object stored in shared memory\n",
    "    with shared_counter.get_lock():      # lock to avoid race conditions\n",
    "        shared_counter.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    counter = multiprocessing.Value(\"i\", 0)  # \"i\" = integer\n",
    "\n",
    "    p1 = multiprocessing.Process(target=increment, args=(counter,))\n",
    "    p2 = multiprocessing.Process(target=increment, args=(counter,))\n",
    "\n",
    "    p1.start(); p2.start()\n",
    "    p1.join();  p2.join()\n",
    "\n",
    "    print(\"Shared counter:\", counter.value)\n",
    "    # OUTPUT: Shared counter: 2\n",
    "\n",
    "\n",
    "# Normal globals are not shared between processes\n",
    "# Use multiprocessing.Value for shared scalars\n",
    "# Always protect shared memory with a lock\n",
    "# This pattern enables safe inter-process mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F) Use multiprocessing.Queue for messages/results\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker(out_q):\n",
    "    out_q.put(\"Hello from child process\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    p = multiprocessing.Process(target=worker, args=(q,))\n",
    "    p.start()\n",
    "    msg = q.get()   # read message from child\n",
    "    p.join()\n",
    "\n",
    "    print(\"Received:\", msg)\n",
    "    # OUTPUT: Received: Hello from child process\n",
    "\n",
    "# Use multiprocessing.Queue to pass data between processes\n",
    "# put() sends data\n",
    "# get() receives data\n",
    "# join() ensures synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6fff4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common rules to be followed:\n",
    "\n",
    "# 1) Always use if __name__ == \"__main__\":\n",
    "# Without it, some systems may repeatedly spawn processes.\n",
    "\n",
    "# 2) Only send “picklable” objects\n",
    "# Processes communicate by serializing data (pickling).\n",
    "# Some objects cannot be pickled easily (open file handles, some lambdas, local functions).\n",
    "\n",
    "# 3) Processes are heavier than threads\n",
    "# - Higher startup cost\n",
    "# - More memory usage\n",
    "# - So use multiprocessing mainly for CPU-bound work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182d017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "545d6111",
   "metadata": {},
   "source": [
    "# Using the `multiprocessing` Module\n",
    "\n",
    "## Why Multiprocessing Is Needed\n",
    "\n",
    "So far, execution has been discussed using **threads**. Threads share memory and are limited by the **Global Interpreter Lock (GIL)** when executing CPU-bound Python code.\n",
    "\n",
    "Multiprocessing exists to solve a different problem.\n",
    "\n",
    "Multiprocessing allows a program to:\n",
    "\n",
    "* Run **multiple processes**\n",
    "* Use **multiple CPU cores**\n",
    "* Execute Python code truly in parallel\n",
    "* Avoid the GIL entirely\n",
    "\n",
    "Each process has its **own Python interpreter and memory space**.\n",
    "\n",
    "---\n",
    "\n",
    "## Process vs Thread (Starting From Basics)\n",
    "\n",
    "### Thread\n",
    "\n",
    "* Runs inside a process\n",
    "* Shares memory with other threads\n",
    "* Limited by the GIL for CPU-bound work\n",
    "* Lightweight and fast to create\n",
    "\n",
    "### Process\n",
    "\n",
    "* Independent execution unit\n",
    "* Own memory space\n",
    "* Own Python interpreter\n",
    "* Can run on a separate CPU core\n",
    "* Heavier than threads but truly parallel\n",
    "\n",
    "Multiprocessing is the correct tool for **CPU-bound workloads**.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is the `multiprocessing` Module?\n",
    "\n",
    "The `multiprocessing` module is part of Python’s standard library.\n",
    "\n",
    "It provides:\n",
    "\n",
    "* Process creation similar to threads\n",
    "* Inter-process communication (IPC)\n",
    "* Shared memory primitives\n",
    "* Process pools for parallel execution\n",
    "\n",
    "Its API is intentionally similar to the `threading` module, making it easier to learn.\n",
    "\n",
    "---\n",
    "\n",
    "## Basic Concept: Running Code in Another Process\n",
    "\n",
    "When using multiprocessing:\n",
    "\n",
    "* The main program starts one or more child processes\n",
    "* Each child process runs independently\n",
    "* Memory is not shared automatically\n",
    "\n",
    "This isolation prevents race conditions but introduces communication challenges.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating a Process (Minimal Example)\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def task():\n",
    "    print(\"Running in a separate process\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = multiprocessing.Process(target=task)\n",
    "    p.start()\n",
    "    p.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `Process` creates a new process\n",
    "* `start()` launches it\n",
    "* `join()` waits for it to finish\n",
    "* The `if __name__ == \"__main__\"` guard is mandatory\n",
    "\n",
    "---\n",
    "\n",
    "## Why the `__main__` Guard Is Required\n",
    "\n",
    "On many systems (especially Windows and macOS):\n",
    "\n",
    "* A new process imports the main module\n",
    "* Without the guard, the process creation code runs again\n",
    "* This leads to infinite process spawning\n",
    "\n",
    "The guard ensures that:\n",
    "\n",
    "* Process creation runs only in the main program\n",
    "* Child processes execute only the target function\n",
    "\n",
    "This is a critical rule in multiprocessing.\n",
    "\n",
    "---\n",
    "\n",
    "## Running Multiple Processes\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker(name):\n",
    "    print(f\"Worker {name} running\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processes = []\n",
    "\n",
    "    for i in range(3):\n",
    "        p = multiprocessing.Process(target=worker, args=(i,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Multiple processes run concurrently\n",
    "* Output order is not guaranteed\n",
    "* Each process runs independently\n",
    "\n",
    "---\n",
    "\n",
    "## Memory Isolation Between Processes\n",
    "\n",
    "Processes do **not share memory by default**.\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = multiprocessing.Process(target=increment)\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print(\"Main counter:\", counter)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The child process modifies its own copy of `counter`\n",
    "* The main process remains unchanged\n",
    "* No shared state exists automatically\n",
    "\n",
    "This behavior avoids many threading problems but requires explicit communication.\n",
    "\n",
    "---\n",
    "\n",
    "## Passing Data to Processes\n",
    "\n",
    "Arguments can be passed to processes at creation time.\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def square(n):\n",
    "    print(n * n)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = multiprocessing.Process(target=square, args=(5,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "```\n",
    "\n",
    "Data passed as arguments is **copied** (serialized) into the child process.\n",
    "\n",
    "---\n",
    "\n",
    "## Returning Results From a Process\n",
    "\n",
    "Processes cannot return values directly like function calls.\n",
    "\n",
    "Instead, multiprocessing provides:\n",
    "\n",
    "* Queues\n",
    "* Pipes\n",
    "* Shared memory objects\n",
    "\n",
    "---\n",
    "\n",
    "## Using a Queue for Inter-Process Communication\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker(q):\n",
    "    q.put(\"Result from process\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = multiprocessing.Queue()\n",
    "    p = multiprocessing.Process(target=worker, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())\n",
    "    p.join()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `Queue` is process-safe\n",
    "* Data is serialized and transferred between processes\n",
    "* This is the most common IPC mechanism\n",
    "\n",
    "---\n",
    "\n",
    "## Multiple Processes Using a Queue\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker(num, q):\n",
    "    q.put(num * num)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = multiprocessing.Queue()\n",
    "    processes = []\n",
    "\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=worker, args=(i, q))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    while not q.empty():\n",
    "        print(q.get())\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Results arrive in unpredictable order\n",
    "* All processes execute independently\n",
    "* The queue safely collects results\n",
    "\n",
    "---\n",
    "\n",
    "## Shared Memory Objects\n",
    "\n",
    "When data must be shared, multiprocessing provides controlled shared memory.\n",
    "\n",
    "### Shared Value\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def increment(shared_value):\n",
    "    with shared_value.get_lock():\n",
    "        shared_value.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    value = multiprocessing.Value(\"i\", 0)\n",
    "    processes = []\n",
    "\n",
    "    for _ in range(5):\n",
    "        p = multiprocessing.Process(target=increment, args=(value,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(\"Final value:\", value.value)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `Value` creates shared memory\n",
    "* A lock is used to ensure safety\n",
    "* Shared memory must still be synchronized\n",
    "\n",
    "---\n",
    "\n",
    "## Shared Arrays\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def modify(arr):\n",
    "    arr[0] += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arr = multiprocessing.Array(\"i\", [0, 1, 2])\n",
    "    p = multiprocessing.Process(target=modify, args=(arr,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print(list(arr))\n",
    "```\n",
    "\n",
    "Shared arrays allow limited shared-state designs.\n",
    "\n",
    "---\n",
    "\n",
    "## Process Pools: Managing Multiple Workers Easily\n",
    "\n",
    "Manually managing processes becomes complex at scale.\n",
    "\n",
    "A **process pool**:\n",
    "\n",
    "* Manages a fixed number of worker processes\n",
    "* Distributes tasks automatically\n",
    "* Reuses processes efficiently\n",
    "\n",
    "---\n",
    "\n",
    "## Using `multiprocessing.Pool`\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
    "        print(results)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* A pool of worker processes is created\n",
    "* Tasks are distributed automatically\n",
    "* Results are collected in order\n",
    "\n",
    "This is the most common multiprocessing pattern.\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use `map`, `apply`, and `apply_async`\n",
    "\n",
    "* `map`: parallel version of built-in `map`\n",
    "* `apply`: run one task in a worker\n",
    "* `apply_async`: non-blocking execution\n",
    "\n",
    "```python\n",
    "with multiprocessing.Pool(2) as pool:\n",
    "    result = pool.apply(square, (5,))\n",
    "    print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## CPU-Bound Performance Advantage\n",
    "\n",
    "Multiprocessing enables true parallelism.\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cpu_task():\n",
    "    count = 0\n",
    "    for _ in range(10_000_000):\n",
    "        count += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "\n",
    "    processes = [\n",
    "        multiprocessing.Process(target=cpu_task),\n",
    "        multiprocessing.Process(target=cpu_task)\n",
    "    ]\n",
    "\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(\"Time taken:\", time.time() - start)\n",
    "```\n",
    "\n",
    "Observation:\n",
    "\n",
    "* Multiple CPU cores are utilized\n",
    "* Execution is faster than threading for CPU-bound work\n",
    "\n",
    "---\n",
    "\n",
    "## Costs of Multiprocessing\n",
    "\n",
    "Multiprocessing is powerful but has trade-offs:\n",
    "\n",
    "* Higher memory usage\n",
    "* Slower startup time\n",
    "* Serialization overhead\n",
    "* More complex debugging\n",
    "\n",
    "It should not be used blindly.\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Multiprocessing\n",
    "\n",
    "Use multiprocessing when:\n",
    "\n",
    "* Work is CPU-bound\n",
    "* Tasks are independent\n",
    "* Data can be partitioned\n",
    "* Parallel execution is required\n",
    "\n",
    "Avoid multiprocessing when:\n",
    "\n",
    "* Tasks are small and short-lived\n",
    "* Data sharing is frequent\n",
    "* Startup overhead dominates execution\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Parallel Computation Using Multiprocessing\n",
    "\n",
    "Create a Python script that:\n",
    "\n",
    "* Computes the square of numbers from 1 to 10\n",
    "* Uses a process pool\n",
    "* Prints the results\n",
    "* Uses the `__main__` guard correctly\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Practice process creation\n",
    "* Use multiprocessing safely\n",
    "* Observe parallel execution\n",
    "\n",
    "The solution should clearly show:\n",
    "\n",
    "* Independent processes running\n",
    "* Correct result collection\n",
    "* Clean program termination\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87c340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a013d75",
   "metadata": {},
   "source": [
    "# Process Pools and Shared Memory Objects\n",
    "\n",
    "## Why This Topic Exists\n",
    "\n",
    "When learning multiprocessing for the first time, two problems appear very quickly:\n",
    "\n",
    "1. **Creating and managing many processes manually is hard**\n",
    "2. **Processes do not share memory by default**\n",
    "\n",
    "To solve these:\n",
    "\n",
    "* **Process Pools** manage worker processes for you\n",
    "* **Shared Memory Objects** allow controlled data sharing between processes\n",
    "\n",
    "This topic starts from absolute basics and builds step by step.\n",
    "\n",
    "---\n",
    "\n",
    "## Recap: What a Process Is (Very Brief)\n",
    "\n",
    "* A process has its **own memory**\n",
    "* A process runs on its **own CPU core**\n",
    "* Processes do **not share variables automatically**\n",
    "* Communication must be explicit\n",
    "\n",
    "This is very different from threads.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 1: Manual Process Management Does Not Scale\n",
    "\n",
    "You already know how to create processes like this:\n",
    "\n",
    "```python\n",
    "p = multiprocessing.Process(target=task)\n",
    "p.start()\n",
    "p.join()\n",
    "```\n",
    "\n",
    "This is fine for:\n",
    "\n",
    "* 1 or 2 processes\n",
    "* Simple demonstrations\n",
    "\n",
    "But it becomes messy when:\n",
    "\n",
    "* You need 10, 50, or 100 tasks\n",
    "* You want to reuse processes\n",
    "* You want results collected automatically\n",
    "\n",
    "This is why **Process Pools** exist.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is a Process Pool?\n",
    "\n",
    "A **Process Pool** is:\n",
    "\n",
    "* A fixed number of worker processes\n",
    "* Created once\n",
    "* Reused to execute many tasks\n",
    "\n",
    "Instead of manually creating processes:\n",
    "\n",
    "* You submit tasks to the pool\n",
    "* The pool assigns tasks to available workers\n",
    "* Results are collected for you\n",
    "\n",
    "Think of it as a **worker team** instead of hiring a new worker for every task.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating a Process Pool (Basic Example)\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def task(n):\n",
    "    return n * n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    results = pool.map(task, [1, 2, 3, 4, 5])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(results)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `processes=4` creates 4 worker processes\n",
    "* `map()` distributes work across workers\n",
    "* Results are returned as a list\n",
    "* The pool is closed and joined cleanly\n",
    "\n",
    "This is the **most common pool usage pattern**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why `map()` Feels Familiar\n",
    "\n",
    "`pool.map()` works like Python’s built-in `map()`:\n",
    "\n",
    "```python\n",
    "map(function, iterable)\n",
    "```\n",
    "\n",
    "But instead of running sequentially:\n",
    "\n",
    "* Each item may run in parallel\n",
    "* Tasks are distributed automatically\n",
    "* CPU cores are utilized efficiently\n",
    "\n",
    "This makes learning pools much easier.\n",
    "\n",
    "---\n",
    "\n",
    "## Using a Pool with a Context Manager (Recommended)\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def task(n):\n",
    "    return n * n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.Pool(4) as pool:\n",
    "        results = pool.map(task, range(6))\n",
    "    print(results)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The pool is created automatically\n",
    "* The pool is cleaned up automatically\n",
    "* This is safer and cleaner than manual close/join\n",
    "\n",
    "Always prefer this pattern.\n",
    "\n",
    "---\n",
    "\n",
    "## Blocking vs Non-Blocking Pool Calls\n",
    "\n",
    "### Blocking Call (`map`)\n",
    "\n",
    "```python\n",
    "results = pool.map(task, data)\n",
    "```\n",
    "\n",
    "* Waits until all tasks finish\n",
    "* Returns results in order\n",
    "* Simple and safe\n",
    "\n",
    "---\n",
    "\n",
    "### Non-Blocking Call (`apply_async`)\n",
    "\n",
    "```python\n",
    "result = pool.apply_async(task, (5,))\n",
    "print(result.get())\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Task runs in background\n",
    "* `get()` waits for the result\n",
    "* Useful for more complex workflows\n",
    "\n",
    "Beginners should start with `map()`.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 2: Processes Do Not Share Memory\n",
    "\n",
    "Consider this example:\n",
    "\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "With multiprocessing:\n",
    "\n",
    "* Each process has its **own copy** of `counter`\n",
    "* Changes do not affect other processes\n",
    "* This avoids race conditions but limits coordination\n",
    "\n",
    "To share data, Python provides **shared memory objects**.\n",
    "\n",
    "---\n",
    "\n",
    "## What Are Shared Memory Objects?\n",
    "\n",
    "Shared memory objects allow:\n",
    "\n",
    "* Multiple processes to access the same memory\n",
    "* Controlled, synchronized updates\n",
    "* Explicit data sharing\n",
    "\n",
    "Multiprocessing provides:\n",
    "\n",
    "* `Value` for single values\n",
    "* `Array` for sequences\n",
    "* Managers for complex objects\n",
    "\n",
    "---\n",
    "\n",
    "## Shared `Value`: Single Shared Variable\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def increment(shared_value):\n",
    "    with shared_value.get_lock():\n",
    "        shared_value.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    value = multiprocessing.Value(\"i\", 0)\n",
    "    processes = []\n",
    "\n",
    "    for _ in range(5):\n",
    "        p = multiprocessing.Process(target=increment, args=(value,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(\"Final value:\", value.value)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* `\"i\"` means integer\n",
    "* `shared_value.value` accesses the data\n",
    "* A lock ensures safe updates\n",
    "* Without the lock, data corruption can occur\n",
    "\n",
    "---\n",
    "\n",
    "## Why Locks Are Still Needed\n",
    "\n",
    "Even though memory is shared:\n",
    "\n",
    "* Multiple processes may write at the same time\n",
    "* Operations are not atomic\n",
    "* Locks prevent overlapping updates\n",
    "\n",
    "Shared memory does **not** mean automatic safety.\n",
    "\n",
    "---\n",
    "\n",
    "## Shared `Array`: Shared Sequence of Values\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def modify(arr):\n",
    "    arr[0] += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arr = multiprocessing.Array(\"i\", [1, 2, 3])\n",
    "    p = multiprocessing.Process(target=modify, args=(arr,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print(list(arr))\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Shared arrays behave like lists\n",
    "* Changes are visible across processes\n",
    "* Best used for numeric data\n",
    "\n",
    "---\n",
    "\n",
    "## Using a Manager for Complex Shared Objects\n",
    "\n",
    "Managers allow sharing:\n",
    "\n",
    "* Lists\n",
    "* Dictionaries\n",
    "* Sets\n",
    "* Custom objects (with limitations)\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def add_item(shared_list):\n",
    "    shared_list.append(\"data\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.Manager() as manager:\n",
    "        shared_list = manager.list()\n",
    "        p = multiprocessing.Process(target=add_item, args=(shared_list,))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        print(shared_list)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Managers use a server process\n",
    "* Slower than shared memory\n",
    "* Easier for beginners and complex data\n",
    "\n",
    "---\n",
    "\n",
    "## Shared Memory vs Queues\n",
    "\n",
    "| Use Case              | Best Tool |\n",
    "| --------------------- | --------- |\n",
    "| Return results        | Queue     |\n",
    "| Stream tasks          | Queue     |\n",
    "| Share counters        | Value     |\n",
    "| Share numeric arrays  | Array     |\n",
    "| Share complex objects | Manager   |\n",
    "| Avoid shared state    | Queue     |\n",
    "\n",
    "Queues are usually safer and simpler than shared memory.\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: Pool + Shared Value\n",
    "\n",
    "This code must be saved as `pool_shared_value_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python pool_shared_value_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def increment(shared_value):\n",
    "    with shared_value.get_lock():\n",
    "        shared_value.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    value = multiprocessing.Value(\"i\", 0)\n",
    "\n",
    "    with multiprocessing.Pool(4) as pool:\n",
    "        pool.starmap(increment, [(value,) for _ in range(10)])\n",
    "\n",
    "    print(\"Final value:\", value.value)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Common Beginner Mistakes\n",
    "\n",
    "* Forgetting `if __name__ == \"__main__\"`\n",
    "* Expecting global variables to be shared\n",
    "* Using shared memory without locks\n",
    "* Creating too many processes\n",
    "* Using multiprocessing for tiny tasks\n",
    "\n",
    "Avoiding these saves hours of debugging.\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Process Pools\n",
    "\n",
    "Use process pools when:\n",
    "\n",
    "* Tasks are CPU-bound\n",
    "* Tasks are independent\n",
    "* Same function runs on many inputs\n",
    "* Results can be collected centrally\n",
    "\n",
    "Avoid pools when:\n",
    "\n",
    "* Tasks are very short\n",
    "* Data transfer dominates computation\n",
    "* Shared state is complex\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Pool + Shared Data\n",
    "\n",
    "Create a Python script that:\n",
    "\n",
    "* Uses a process pool\n",
    "* Squares numbers from 1 to 10\n",
    "* Stores results in a shared list using a Manager\n",
    "* Prints the final shared list\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Practice pool creation\n",
    "* Practice shared data usage\n",
    "* Observe process coordination\n",
    "\n",
    "The solution should demonstrate:\n",
    "\n",
    "* Parallel execution\n",
    "* Correct data sharing\n",
    "* Clean shutdown\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8456b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-Process Communication (IPC) and Data Serialization\n",
    "\n",
    "# 1) First, what is the problem?\n",
    "# When you use multiprocessing, you create separate processes.\n",
    "# Each process has its own memory (its own private variables).\n",
    "\n",
    "# So if a child process changes a normal Python variable, the main process will not see it.\n",
    "# That is why we need IPC.\n",
    "\n",
    "\n",
    "# What is IPC?\n",
    "# IPC (Inter-Process Communication) means:\n",
    "# Ways for one process to send data to another process.\n",
    "    \n",
    "# Common IPC tools in Python:\n",
    "# - Queue (most common, easiest)\n",
    "# - Pipe (two-way connection between two processes)\n",
    "# - Shared memory (Value, Array, shared_memory) (fast for simple data)\n",
    "# - Manager (shared dict/list across processes, slower but convenient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edb77dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Data Serialization?\n",
    "# When a process sends data to another process, Python must convert that data into a form that can travel between processes.\n",
    "# This conversion is called serialization.\n",
    "\n",
    "# In Python multiprocessing, serialization usually happens using pickle.\n",
    "\n",
    "# So:\n",
    "# Serialization = Convert Python object → bytes (sendable form)\n",
    "# Deserialization = Convert bytes → Python object (usable form)\n",
    "\n",
    "# Note:\n",
    "# IPC often requires serialization, because processes don’t share normal memory.\n",
    "\n",
    "# Why is Serialization needed?\n",
    "# Processes are like separate rooms.\n",
    "# To send something from Room A to Room B, you can’t “point to the same object”.\n",
    "# You must pack the data and send it.\n",
    "# That “packing” is serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) IPC using multiprocessing.Queue (Most common)\n",
    "# Goal:\n",
    "# Child process calculates a result and sends it back to main process.\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker(out_q):\n",
    "    # This function runs inside the child process\n",
    "    result = 10 * 10                 # do some work in child\n",
    "    out_q.put(result)                # send result to main process via Queue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out_q = multiprocessing.Queue()  # Queue is safe for processes (IPC tool)\n",
    "\n",
    "    p = multiprocessing.Process(\n",
    "        target=worker,               # child process will run worker()\n",
    "        args=(out_q,)                # give the Queue to child\n",
    "    )\n",
    "\n",
    "    p.start()                        # start child process\n",
    "    value = out_q.get()              # main process waits and receives data\n",
    "    p.join()                         # ensure child has finished\n",
    "\n",
    "    print(\"Received from child:\", value)\n",
    "    # OUTPUT: Received from child: 100\n",
    "\n",
    "# # In this example, we understand:\n",
    "# Processes do not share memory\n",
    "# Data must be passed explicitly using IPC tools\n",
    "\n",
    "# multiprocessing.Queue:\n",
    "# is safe\n",
    "# blocks correctly\n",
    "# serializes objects automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9aa05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) IPC using multiprocessing.Pipe (Two processes talk directly)\n",
    "# Pipe is like a private phone line between two endpoints.\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker(conn):\n",
    "    # conn is one end of the pipe (child side)\n",
    "    conn.send(\"Hello from child\")    # send message to parent\n",
    "    conn.close()                     # close this end when done\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parent_conn, child_conn = multiprocessing.Pipe()\n",
    "    # parent_conn stays in main process\n",
    "    # child_conn will be passed to child process\n",
    "\n",
    "    p = multiprocessing.Process(target=worker, args=(child_conn,))\n",
    "    p.start()\n",
    "\n",
    "    msg = parent_conn.recv()         # receive message from child (blocks until available)\n",
    "    p.join()\n",
    "\n",
    "    print(\"Message:\", msg)\n",
    "    # OUTPUT: Message: Hello from child\n",
    "\n",
    "\n",
    "# Our understanding from this code:\n",
    "# multiprocessing.Pipe creates a direct communication channel\n",
    "\n",
    "# Pipes are:\n",
    "# faster than queues for one-to-one communication\n",
    "# suitable for simple request/response patterns\n",
    "# Processes still do not share memory\n",
    "# Data must be explicitly sent\n",
    "\n",
    "# Pipe vs Queue:\n",
    "# Pipe\n",
    "# point-to-point\n",
    "# low overhead\n",
    "# manual control\n",
    "\n",
    "# Queue\n",
    "# many-to-many\n",
    "# safer for complex workflows\n",
    "# higher overhead\n",
    "\n",
    "# When to prefer Pipe\n",
    "# Simple communication between exactly two processes\n",
    "# Slightly lower overhead than Queue\n",
    "# But Queue is easier for beginners and supports many producers/consumers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10422338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "{'name': 'Asha', 'scores': [10, 20, 30]}\n"
     ]
    }
   ],
   "source": [
    "# Serialization\n",
    "# C) What does serialization look like?\n",
    "# We can demonstrate with pickle (same idea multiprocessing uses).\n",
    "\n",
    "import pickle\n",
    "\n",
    "data = {\"name\": \"Asha\", \"scores\": [10, 20, 30]}\n",
    "\n",
    "packed = pickle.dumps(data)     # serialize: Python object -> bytes\n",
    "print(type(packed))\n",
    "# OUTPUT: <class 'bytes'>\n",
    "\n",
    "unpacked = pickle.loads(packed) # deserialize: bytes -> Python object\n",
    "print(unpacked)\n",
    "# OUTPUT: {'name': 'Asha', 'scores': [10, 20, 30]}\n",
    "\n",
    "# Important Caution:\n",
    "# Never unpickle data from untrusted sources\n",
    "# Pickle can execute arbitrary code during loading\n",
    "# It is not secure against malicious input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not everything can be serialized (pickled)\n",
    "\n",
    "# Some objects cannot be easily sent to another process:\n",
    "# open file handles\n",
    "# sockets (directly)\n",
    "# database connections\n",
    "# generators\n",
    "# lambdas (often)\n",
    "# nested/local functions (often)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0233cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a common serialization failure\n",
    "# (Do not run this in production; this is for learning.)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    f = open(\"sample.txt\", \"w\")      # file handle (not safe to pickle)\n",
    "\n",
    "    try:\n",
    "        q.put(f)                     # tries to serialize file object -> usually fails\n",
    "    except Exception as e:\n",
    "        print(\"Serialization failed:\", e)\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe64f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Memory vs Serialization\n",
    "# Queue/Pipe usually serialize (pickle) data.\n",
    "\n",
    "# Shared memory tools avoid copying:\n",
    "# - multiprocessing.Value\n",
    "# - multiprocessing.Array\n",
    "# - multiprocessing.shared_memory (advanced)\n",
    "\n",
    "# Use shared memory for:\n",
    "# - large numeric data\n",
    "# - performance-critical cases\n",
    "\n",
    "# Use Queue/Pipe for:\n",
    "# - general Python objects\n",
    "# - simple IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc19e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # E) Shared memory example (no pickling for the shared value itself)\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# def worker(shared_num):\n",
    "#     # shared_num is stored in shared memory\n",
    "#     shared_num.value += 5            # child modifies the shared value directly\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     num = multiprocessing.Value(\"i\", 10)  # shared integer starting at 10\n",
    "\n",
    "#     p = multiprocessing.Process(target=worker, args=(num,))\n",
    "#     p.start()\n",
    "#     p.join()\n",
    "\n",
    "#     print(\"Shared value:\", num.value)\n",
    "#     # OUTPUT: Shared value: 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518bcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f8de329",
   "metadata": {},
   "source": [
    "# Best Use Cases for Processes vs Threads\n",
    "\n",
    "## Why This Comparison Matters\n",
    "\n",
    "When building concurrent or parallel Python programs, one of the most important design decisions is choosing between:\n",
    "\n",
    "* **Threads**\n",
    "* **Processes**\n",
    "\n",
    "Choosing the wrong one can lead to:\n",
    "\n",
    "* Poor performance\n",
    "* Unnecessary complexity\n",
    "* Wasted system resources\n",
    "* Hard-to-debug bugs\n",
    "\n",
    "This topic explains **from first principles** when and why to use each approach.\n",
    "\n",
    "---\n",
    "\n",
    "## Starting From the Basics\n",
    "\n",
    "Before comparing, it is important to clearly understand what threads and processes are.\n",
    "\n",
    "### Thread (Basic Definition)\n",
    "\n",
    "* A thread runs inside a process\n",
    "* Threads share the same memory\n",
    "* Threads are lightweight\n",
    "* Context switching is fast\n",
    "\n",
    "### Process (Basic Definition)\n",
    "\n",
    "* A process has its own memory\n",
    "* Processes do not share data automatically\n",
    "* Each process has its own Python interpreter\n",
    "* Processes can run on separate CPU cores\n",
    "\n",
    "These fundamental differences drive all use cases.\n",
    "\n",
    "---\n",
    "\n",
    "## The Role of the GIL in Python\n",
    "\n",
    "In CPython:\n",
    "\n",
    "* Only one thread executes Python bytecode at a time\n",
    "* This is enforced by the Global Interpreter Lock (GIL)\n",
    "\n",
    "Implication:\n",
    "\n",
    "* Threads do **not** run Python code in parallel on multiple cores\n",
    "* Processes **do** run in parallel\n",
    "\n",
    "This single fact is central to choosing between threads and processes.\n",
    "\n",
    "---\n",
    "\n",
    "## CPU-Bound Workloads\n",
    "\n",
    "### What Is CPU-Bound Work?\n",
    "\n",
    "CPU-bound work:\n",
    "\n",
    "* Spends most time doing computation\n",
    "* Uses CPU heavily\n",
    "* Has little waiting\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Image processing\n",
    "* Data compression\n",
    "* Numerical simulations\n",
    "* Cryptographic calculations\n",
    "\n",
    "---\n",
    "\n",
    "### Threads for CPU-Bound Work\n",
    "\n",
    "Threads:\n",
    "\n",
    "* Compete for the GIL\n",
    "* Run one at a time\n",
    "* Do not scale across cores\n",
    "\n",
    "Result:\n",
    "\n",
    "* Multiple threads may be slower than one thread\n",
    "* No true parallelism\n",
    "\n",
    "Threads are a poor choice for CPU-bound work.\n",
    "\n",
    "---\n",
    "\n",
    "### Processes for CPU-Bound Work\n",
    "\n",
    "Processes:\n",
    "\n",
    "* Each process has its own GIL\n",
    "* Can run simultaneously on multiple cores\n",
    "* Scale with CPU availability\n",
    "\n",
    "Result:\n",
    "\n",
    "* True parallel execution\n",
    "* Significant speedup\n",
    "\n",
    "Processes are the correct choice for CPU-bound workloads.\n",
    "\n",
    "---\n",
    "\n",
    "## I/O-Bound Workloads\n",
    "\n",
    "### What Is I/O-Bound Work?\n",
    "\n",
    "I/O-bound work:\n",
    "\n",
    "* Spends most time waiting\n",
    "* Waits on disk, network, APIs, or databases\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Web scraping\n",
    "* File downloads\n",
    "* Network services\n",
    "* Logging systems\n",
    "\n",
    "---\n",
    "\n",
    "### Threads for I/O-Bound Work\n",
    "\n",
    "Threads:\n",
    "\n",
    "* Release the GIL during I/O\n",
    "* Allow other threads to run\n",
    "* Overlap waiting time\n",
    "\n",
    "Result:\n",
    "\n",
    "* High throughput\n",
    "* Efficient resource usage\n",
    "* Low overhead\n",
    "\n",
    "Threads are an excellent choice for I/O-bound workloads.\n",
    "\n",
    "---\n",
    "\n",
    "### Processes for I/O-Bound Work\n",
    "\n",
    "Processes:\n",
    "\n",
    "* Also work for I/O-bound tasks\n",
    "* Have higher overhead\n",
    "* Require IPC for data sharing\n",
    "\n",
    "Result:\n",
    "\n",
    "* Often unnecessary complexity\n",
    "* Slower startup and higher memory usage\n",
    "\n",
    "Threads are usually preferred for I/O-bound work.\n",
    "\n",
    "---\n",
    "\n",
    "## Memory Sharing Considerations\n",
    "\n",
    "### Threads\n",
    "\n",
    "* Share memory naturally\n",
    "* Easy data access\n",
    "* High risk of race conditions\n",
    "* Require careful synchronization\n",
    "\n",
    "### Processes\n",
    "\n",
    "* Do not share memory\n",
    "* Safer isolation\n",
    "* Explicit IPC required\n",
    "* Fewer accidental data corruption bugs\n",
    "\n",
    "Choice depends on whether shared state is required.\n",
    "\n",
    "---\n",
    "\n",
    "## Fault Isolation and Stability\n",
    "\n",
    "### Threads\n",
    "\n",
    "* A crash in one thread can crash the whole process\n",
    "* Bugs can corrupt shared memory\n",
    "* Harder to isolate failures\n",
    "\n",
    "### Processes\n",
    "\n",
    "* Process crashes are isolated\n",
    "* One process failing does not crash others\n",
    "* Better fault tolerance\n",
    "\n",
    "For critical systems, processes provide stronger safety guarantees.\n",
    "\n",
    "---\n",
    "\n",
    "## Resource Usage Comparison\n",
    "\n",
    "| Aspect          | Threads | Processes |\n",
    "| --------------- | ------- | --------- |\n",
    "| Startup cost    | Low     | High      |\n",
    "| Memory usage    | Low     | High      |\n",
    "| CPU parallelism | No      | Yes       |\n",
    "| Data sharing    | Easy    | Explicit  |\n",
    "| Fault isolation | Weak    | Strong    |\n",
    "| Debugging       | Hard    | Easier    |\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Use Case Scenarios\n",
    "\n",
    "### Use Threads When:\n",
    "\n",
    "* Work is I/O-bound\n",
    "* Many tasks spend time waiting\n",
    "* Shared memory simplifies design\n",
    "* Latency is critical\n",
    "* Tasks are lightweight\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Web crawlers\n",
    "* Network clients\n",
    "* API gateways\n",
    "* Concurrent file readers\n",
    "\n",
    "---\n",
    "\n",
    "### Use Processes When:\n",
    "\n",
    "* Work is CPU-bound\n",
    "* Parallel execution is required\n",
    "* Tasks are independent\n",
    "* Fault isolation is important\n",
    "* Memory safety matters\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Data analytics pipelines\n",
    "* Video encoding\n",
    "* Scientific computing\n",
    "* Batch processing jobs\n",
    "\n",
    "---\n",
    "\n",
    "## Combining Threads and Processes\n",
    "\n",
    "Many real systems use **both**.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Processes handle CPU-heavy tasks\n",
    "* Each process uses threads for I/O\n",
    "* This maximizes CPU usage and responsiveness\n",
    "\n",
    "This hybrid model is common in production systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Simple Comparison Example (Conceptual)\n",
    "\n",
    "```python\n",
    "# I/O-bound\n",
    "threads -> good choice\n",
    "\n",
    "# CPU-bound\n",
    "processes -> good choice\n",
    "```\n",
    "\n",
    "This simple rule solves most beginner decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## Script-Based Demonstration: Threads vs Processes\n",
    "\n",
    "This code must be saved as `threads_vs_processes_demo.py` and executed from the terminal using:\n",
    "\n",
    "```\n",
    "python threads_vs_processes_demo.py\n",
    "```\n",
    "\n",
    "It should not be run inside a Jupyter Notebook.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cpu_task():\n",
    "    total = 0\n",
    "    for _ in range(10_000_000):\n",
    "        total += 1\n",
    "\n",
    "def run_threads():\n",
    "    threads = [threading.Thread(target=cpu_task) for _ in range(2)]\n",
    "    start = time.time()\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    print(\"Threads time:\", time.time() - start)\n",
    "\n",
    "def run_processes():\n",
    "    processes = [multiprocessing.Process(target=cpu_task) for _ in range(2)]\n",
    "    start = time.time()\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    print(\"Processes time:\", time.time() - start)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_threads()\n",
    "    run_processes()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Common Beginner Mistakes\n",
    "\n",
    "* Using threads for CPU-heavy tasks\n",
    "* Expecting threads to use multiple cores\n",
    "* Sharing large data across processes\n",
    "* Overusing multiprocessing for simple I/O tasks\n",
    "* Ignoring startup overhead\n",
    "\n",
    "Understanding trade-offs prevents these mistakes.\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Guide (Simple Rule)\n",
    "\n",
    "Ask these questions:\n",
    "\n",
    "1. Is the task CPU-heavy?\n",
    "\n",
    "   * Yes → Use processes\n",
    "   * No → Continue\n",
    "\n",
    "2. Is the task mostly waiting for I/O?\n",
    "\n",
    "   * Yes → Use threads\n",
    "   * No → Re-evaluate design\n",
    "\n",
    "This rule works for most real-world cases.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise: Choosing the Right Tool\n",
    "\n",
    "Given the following tasks, decide whether to use threads or processes:\n",
    "\n",
    "1. Downloading files from multiple URLs\n",
    "2. Calculating prime numbers\n",
    "3. Reading multiple log files from disk\n",
    "4. Image resizing\n",
    "5. Sending API requests\n",
    "\n",
    "Objective:\n",
    "\n",
    "* Apply workload analysis\n",
    "* Choose appropriate concurrency model\n",
    "* Justify the choice\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde4053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "492517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 4C: Async Programming \n",
    "# • asyncio framework overview \n",
    "# • Writing async coroutines and tasks \n",
    "# • Integrating async I/O with APIs and databases \n",
    "# • Combining async, threading, and multiprocessing safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00cfdf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async Programming\n",
    "# Async programming helps when your program spends a lot of time waiting (network, DB, file I/O).\n",
    "# Instead of creating many threads, async uses one thread and switches between tasks while they wait.\n",
    "\n",
    "# What problem does async solve?\n",
    "# Many real programs do this:\n",
    "# - call an API → wait\n",
    "# - query DB → wait\n",
    "# - download something → wait\n",
    "# If you do these one-by-one, total time becomes very large.\n",
    "\n",
    "\n",
    "# Key Terms:\n",
    "# a) Event loop\n",
    "# The event loop is like a manager:\n",
    "# - it runs async tasks\n",
    "# - it pauses tasks that are waiting\n",
    "# - it resumes tasks when they are ready\n",
    "# In asyncio, the event loop is managed by asyncio.run(...).\n",
    "\n",
    "# b) Coroutine (async def)\n",
    "# A coroutine is a special function declared with async def.\n",
    "# It can pause itself using await.\n",
    "\n",
    "# c) await\n",
    "# await means:\n",
    "# “Pause here until this operation finishes, and let the event loop run other tasks meanwhile.”\n",
    "\n",
    "# d) Task\n",
    "# A Task is a coroutine that has been scheduled to run concurrently by the event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de8b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asyncio framework overview\n",
    "# # The asyncio module provides tools to write async code in Python.\n",
    "# It provides:\n",
    "# - event loop management\n",
    "# - async/await syntax\n",
    "# - high-level APIs for async I/O\n",
    "# - tools like asyncio.sleep, asyncio.gather, etc. for common patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d90c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-1\n",
      "file-2\n",
      "file-3\n",
      "Time taken: 6.015554666519165\n"
     ]
    }
   ],
   "source": [
    "# Why normal code is slow (sequential)\n",
    "\n",
    "import time\n",
    "\n",
    "def download_simulation(n):\n",
    "    time.sleep(2)  # blocking sleep (pretend it's network wait)\n",
    "    return f\"file-{n}\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(download_simulation(1))\n",
    "print(download_simulation(2))\n",
    "print(download_simulation(3))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "# OUTPUT (approx):\n",
    "# file-1\n",
    "# file-2\n",
    "# file-3\n",
    "# Time taken: ~6.0\n",
    "\n",
    "# Note: Meaning: each call blocks, so total time adds up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700156f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async version\n",
    "\n",
    "# A) Write an async coroutine\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def download_simulation(n):\n",
    "    # asyncio.sleep is non-blocking (it yields control to event loop)\n",
    "    await asyncio.sleep(2)\n",
    "    return f\"file-{n}\"\n",
    "\n",
    "async def main():\n",
    "    start = time.time()\n",
    "\n",
    "    # schedule 3 downloads concurrently\n",
    "    results = await asyncio.gather(\n",
    "        download_simulation(1),\n",
    "        download_simulation(2),\n",
    "        download_simulation(3),\n",
    "    )\n",
    "\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Time taken:\", end - start)\n",
    "\n",
    "asyncio.run(main())\n",
    "\n",
    "# OUTPUT (approx):\n",
    "# file-1\n",
    "# file-2\n",
    "# file-3\n",
    "# Time taken: ~2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing async coroutines and tasks\n",
    "# Calling an async function gives you a coroutine object, it does NOT run immediately.\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def hello():\n",
    "    await asyncio.sleep(1)\n",
    "    return \"Hello\"\n",
    "\n",
    "async def main():\n",
    "    c = hello()             # coroutine created, not running yet\n",
    "    print(c)\n",
    "    # OUTPUT: <coroutine object hello at ...>\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task (scheduled to run)\n",
    "# To start it concurrently, you wrap it in a Task.\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def hello():\n",
    "    await asyncio.sleep(1)\n",
    "    return \"Hello\"\n",
    "\n",
    "async def main():\n",
    "    t = asyncio.create_task(hello())  # scheduled immediately\n",
    "    result = await t                  # wait for task to finish\n",
    "    print(result)\n",
    "    # OUTPUT: Hello\n",
    "\n",
    "asyncio.run(main())\n",
    "\n",
    "\n",
    "# asyncio.create_task():\n",
    "# schedules a coroutine immediately\n",
    "# allows it to run concurrently with other tasks\n",
    "\n",
    "# await task:\n",
    "# waits for the task’s completion\n",
    "# retrieves its return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119580f",
   "metadata": {},
   "source": [
    "| Code                       | Behavior                            |\n",
    "| -------------------------- | ----------------------------------- |\n",
    "| `c = hello()`              | Coroutine created, **not running**  |\n",
    "| `t = create_task(hello())` | Coroutine scheduled and **running** |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae70543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Integrating async I/O with APIs and databases\n",
    "\n",
    "# Async is best when using libraries that support async, like:\n",
    "# - HTTP clients: aiohttp, httpx (async mode)\n",
    "# - DB drivers: asyncpg (Postgres), aiomysql, motor (MongoDB)\n",
    "# - Redis: redis.asyncio\n",
    "\n",
    "# Async works best when the library provides awaitable operations.\n",
    "# If the library is blocking (normal requests/DB driver), it will block the event loop.\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def fake_api_call(user_id):\n",
    "    print(\"API: fetching user\", user_id)\n",
    "    await asyncio.sleep(1)          # pretend network wait (non-blocking)\n",
    "    return {\"id\": user_id, \"name\": \"User\" + str(user_id)}\n",
    "\n",
    "async def fake_db_save(user):\n",
    "    print(\"DB: saving\", user[\"id\"])\n",
    "    await asyncio.sleep(1)          # pretend DB wait (non-blocking)\n",
    "    return True\n",
    "\n",
    "async def main():\n",
    "    # run multiple API calls concurrently\n",
    "    users = await asyncio.gather(\n",
    "        fake_api_call(1),\n",
    "        fake_api_call(2),\n",
    "        fake_api_call(3),\n",
    "    )\n",
    "\n",
    "    # then save them concurrently too\n",
    "    saves = await asyncio.gather(*(fake_db_save(u) for u in users))\n",
    "\n",
    "    print(\"Saved:\", saves)\n",
    "    # OUTPUT: Saved: [True, True, True]\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d46b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining async, threading, and multiprocessing safely\n",
    "# The simple rule (very important)\n",
    "# - Async is great for I/O-bound\n",
    "# - Multiprocessing is best for CPU-bound\n",
    "# - Threads are useful for blocking I/O libraries that have no async support\n",
    "\n",
    "# Why do we combine them?\n",
    "# Because sometimes you have:\n",
    "# - async web server (asyncio)\n",
    "# - but you must call a blocking library (thread)\n",
    "# - and you must run heavy computation (process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Running blocking code safely inside asyncio (use a thread)\n",
    "# If you call blocking functions directly, you freeze the event loop.\n",
    "# So you offload blocking work to a thread.\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "def blocking_work():\n",
    "    time.sleep(2)           # blocking sleep\n",
    "    return \"blocking done\"\n",
    "\n",
    "async def main():\n",
    "    # run blocking_work in a separate thread so event loop stays free\n",
    "    result = await asyncio.to_thread(blocking_work)\n",
    "\n",
    "    print(result)\n",
    "    # OUTPUT: blocking done\n",
    "\n",
    "asyncio.run(main())\n",
    "\n",
    "# Use asyncio.to_thread() to run blocking functions in async programs\n",
    "# Ideal for:\n",
    "# legacy synchronous code\n",
    "# CPU-light but blocking I/O\n",
    "\n",
    "# Keeps async code fast and responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Running CPU-heavy work safely inside asyncio (use a process)\n",
    "# CPU-heavy work blocks everything (even in async).\n",
    "# So push CPU work into a separate process.\n",
    "\n",
    "import asyncio\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def cpu_heavy(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_running_loop()\n",
    "\n",
    "    # create a process pool for CPU heavy tasks\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "        # run cpu_heavy in another process\n",
    "        result = await loop.run_in_executor(pool, cpu_heavy, 50_000_000)\n",
    "\n",
    "    print(\"CPU result:\", result)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d1b24",
   "metadata": {},
   "source": [
    "| Task type         | Best tool             |\n",
    "| ----------------- | --------------------- |\n",
    "| I/O-bound         | `asyncio`             |\n",
    "| Blocking sync I/O | `asyncio.to_thread()` |\n",
    "| CPU-bound         | `ProcessPoolExecutor` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abb036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Guide:\n",
    "# Use asyncio when:\n",
    "# many API calls\n",
    "# many DB queries (async driver)\n",
    "# many sockets, web scraping, web servers\n",
    "\n",
    "# Use threads when:\n",
    "# you must call blocking libraries inside async\n",
    "# file operations or legacy code blocks the event loop\n",
    "\n",
    "# Use processes when:\n",
    "# CPU heavy tasks (encryption, compression, ML preprocessing, large loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58bd34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Choosing the Right Tool\n",
    "# Given the following tasks, decide whether to use threads or processes:\n",
    "\n",
    "# Downloading files from multiple URLs\n",
    "# Calculating prime numbers\n",
    "# Reading multiple log files from disk\n",
    "# Image resizing\n",
    "# Sending API requests\n",
    "# Objective:\n",
    "\n",
    "# Apply workload analysis\n",
    "# Choose appropriate concurrency model\n",
    "# Justify the choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70a1dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Writing Your Own Async Tasks\n",
    "# Create an asyncio program that:\n",
    "\n",
    "# Defines three coroutines\n",
    "# Each coroutine waits for a different time\n",
    "# Each returns a string\n",
    "# All are scheduled using create_task\n",
    "# Results are collected using gather\n",
    "# Objective:\n",
    "\n",
    "# Practice writing coroutines\n",
    "# Practice creating tasks\n",
    "# Observe concurrent execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd2bb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: API + Async Thinking\n",
    "# Create an asyncio program that:\n",
    "\n",
    "# Simulates calling three APIs\n",
    "# Each waits for a different time\n",
    "# Prints start and end messages\n",
    "# Runs all calls concurrently\n",
    "# Objective:\n",
    "\n",
    "# Practice async I/O thinking\n",
    "# Understand waiting vs blocking\n",
    "# Observe overlapping execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Hybrid Concurrency Practice\n",
    "# Create a program that:\n",
    "\n",
    "# Runs two async tasks concurrently\n",
    "# Calls a blocking function using to_thread\n",
    "# Runs a CPU-heavy function using a process pool\n",
    "# Prints execution order clearly\n",
    "# Objective:\n",
    "\n",
    "# Practice correct delegation\n",
    "# Keep the event loop responsive\n",
    "# Use each model for its strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce3527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "002fde84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Project Problem Statement\n",
    "\n",
    "## Build a Polite and Efficient Async Web Scraper Using Python\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Modern applications often need to retrieve data from multiple web pages. When this is done using traditional synchronous HTTP requests, the program becomes slow because each request blocks execution until it completes.\n",
    "\n",
    "Asynchronous programming allows a program to send multiple requests concurrently and efficiently utilize waiting time caused by network delays.\n",
    "\n",
    "In this project, you will build an **asynchronous web scraper** using Python that demonstrates how concurrency improves performance while following responsible scraping practices.\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Design and implement a Python-based asynchronous web scraper that:\n",
    "\n",
    "* Sends multiple HTTP requests concurrently\n",
    "* Reuses a single HTTP client session\n",
    "* Limits the number of concurrent requests\n",
    "* Handles network errors gracefully\n",
    "* Prints meaningful information for each fetched page\n",
    "\n",
    "The program must be executed from the **terminal** and not from a Jupyter Notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Website to Scrape\n",
    "\n",
    "Use the following website for scraping:\n",
    "\n",
    "```\n",
    "https://quotes.toscrape.com\n",
    "```\n",
    "\n",
    "Reasons for choosing this site:\n",
    "\n",
    "* Designed specifically for web scraping practice\n",
    "* No authentication required\n",
    "* Lightweight and predictable HTML structure\n",
    "* Widely accepted for educational demonstrations\n",
    "\n",
    "You will scrape multiple paginated pages such as:\n",
    "\n",
    "```\n",
    "https://quotes.toscrape.com/page/1/\n",
    "https://quotes.toscrape.com/page/2/\n",
    "https://quotes.toscrape.com/page/3/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Step-by-Step Problem Breakdown\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Understand the Scraping Problem\n",
    "\n",
    "**Task**\n",
    "Explain what a web scraper is and why asynchronous programming is suitable for web scraping.\n",
    "\n",
    "**Hint**\n",
    "Focus on network waiting time and how concurrency reduces idle time during HTTP requests.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Install Required Libraries\n",
    "\n",
    "**Task**\n",
    "Prepare the Python environment to support asynchronous HTTP requests.\n",
    "\n",
    "**Hint**\n",
    "Only one external library is required, and installation must be done using the command line.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Create an Async Function to Fetch One Page\n",
    "\n",
    "**Task**\n",
    "Write an asynchronous function that sends an HTTP GET request and returns the HTML content of a page.\n",
    "\n",
    "**Hint**\n",
    "Use `async def`, `await`, and avoid blocking operations.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Reuse a Single HTTP Client Session\n",
    "\n",
    "**Task**\n",
    "Modify the fetch logic so that all requests reuse a single HTTP client session.\n",
    "\n",
    "**Hint**\n",
    "Creating a new session per request is inefficient. Use a shared session and manage it with a context manager.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Fetch Multiple Pages Concurrently\n",
    "\n",
    "**Task**\n",
    "Fetch multiple pages from the target website concurrently.\n",
    "\n",
    "**Hint**\n",
    "Create a list of asynchronous tasks and execute them using `asyncio.gather()`.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Add Error Handling and Timeouts\n",
    "\n",
    "**Task**\n",
    "Ensure the scraper does not crash when a request fails or times out.\n",
    "\n",
    "**Hint**\n",
    "Use `try-except` blocks and configure request timeouts.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 7: Limit Concurrent Requests\n",
    "\n",
    "**Task**\n",
    "Prevent the scraper from sending too many requests at the same time.\n",
    "\n",
    "**Hint**\n",
    "Use `asyncio.Semaphore` to control the maximum number of concurrent requests.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 8: Display Useful Output\n",
    "\n",
    "**Task**\n",
    "For each fetched page, print the URL, response status, and size of the downloaded content.\n",
    "\n",
    "**Hint**\n",
    "This output helps verify concurrency and successful execution.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 9: Run the Script From the Terminal\n",
    "\n",
    "**Task**\n",
    "Execute the scraper as a standalone Python script.\n",
    "\n",
    "**Hint**\n",
    "Use `asyncio.run(main())` and save the file as `async_web_scraper.py`.\n",
    "\n",
    "---\n",
    "\n",
    "# Constraints\n",
    "\n",
    "* Do not use the `requests` library\n",
    "* Do not block the event loop\n",
    "* Reuse a single HTTP session\n",
    "* Respect polite scraping practices\n",
    "* Do not scrape authenticated or private data\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Learning Outcomes\n",
    "\n",
    "After completing this project, you should be able to:\n",
    "\n",
    "* Explain why asynchronous programming improves web scraping performance\n",
    "* Use `asyncio` and `aiohttp` effectively\n",
    "* Implement concurrency control in network-based programs\n",
    "* Build a production-ready async scraping foundation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2541796",
   "metadata": {},
   "source": [
    "# Happy Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
